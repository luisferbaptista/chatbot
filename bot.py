import os
import signal
import asyncio
import json
import tempfile
import shutil
import io
from typing import Optional, Dict, List
from datetime import datetime

from dotenv import load_dotenv  # pyright: ignore[reportMissingImports]
import httpx  # pyright: ignore[reportMissingImports]
from google.oauth2 import service_account  # pyright: ignore[reportMissingImports]
from google.auth.transport.requests import Request as GoogleRequest  # pyright: ignore[reportMissingImports]

# Sistema de gestiÃ³n de perfiles
try:
    from profile_manager import ProfileManager
    PROFILES_AVAILABLE = True
except ImportError:
    print("Profile management not available")
    PROFILES_AVAILABLE = False

# procesamiento de voz
try:
    import whisper
    from pydub import AudioSegment
    from gtts import gTTS
    VOICE_AVAILABLE = True
except ImportError as e:
    print(f"Voice processing not available: {e}")
    VOICE_AVAILABLE = False

# procesamiento de excel y graficos
try:
    import pandas as pd
    import matplotlib.pyplot as plt
    import plotly.graph_objects as go
    import plotly.express as px
    from plotly.io import to_image
    import io
    import base64
    EXCEL_CHARTS_AVAILABLE = True
except ImportError as e:
    print(f"Excel and chart processing not available: {e}")
    EXCEL_CHARTS_AVAILABLE = False

import requests

# cargar .env early so environment variables are available
try:
    load_dotenv()
except Exception:
    # ignorar errores de carga de .env; usar variables de entorno directamente
    pass
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes

# leer token desde entorno para seguridad. Puedes establecer TELEGRAM_BOT_TOKEN en tu shell
# or use a .env file during development.
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

if not TOKEN:
    # fallback: mantener token hard-coded como Ãºltimo recurso (no recomendado)
    TOKEN = "8035861851:AAFim2hjCQr0Mk56RwNoTpkeVhiONTnHPGA"

# almacenamiento de memoria para conversaciones
CONVERSATION_MEMORY: Dict[int, List[Dict]] = {}
MEMORY_FILE = "conversation_memory.json"
MAX_MEMORY_ENTRIES = 20  # mÃ¡ximo de turnos de conversaciÃ³n para mantener por chat

# gestiÃ³n de perfiles del bot
if PROFILES_AVAILABLE:
    PROFILE_MANAGER = ProfileManager()
else:
    PROFILE_MANAGER = None

# configuraciÃ³n de procesamiento de voz
WHISPER_MODEL_NAME = os.getenv("WHISPER_MODEL", "base")
AUDIO_RESPONSE_ENABLED = os.getenv("AUDIO_RESPONSE_ENABLED", "true").lower() == "true"
WHISPER_MODEL = None  # se cargarÃ¡ en el primer uso


def load_memory():
    """Load conversation memory from file"""
    global CONVERSATION_MEMORY
    try:
        if os.path.exists(MEMORY_FILE):
            with open(MEMORY_FILE, 'r', encoding='utf-8') as f:
                CONVERSATION_MEMORY = json.load(f)
    except Exception as e:
        print(f"Error loading memory: {e}")
        CONVERSATION_MEMORY = {}

def save_memory():
    """Save conversation memory to file"""
    try:
        with open(MEMORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(CONVERSATION_MEMORY, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"Error saving memory: {e}")

def get_chat_memory(chat_id: int) -> List[Dict]:
    """Get conversation history for a chat"""
    return CONVERSATION_MEMORY.get(chat_id, [])

def add_to_memory(chat_id: int, role: str, content: str):
    """Add a message to conversation memory"""
    if chat_id not in CONVERSATION_MEMORY:
        CONVERSATION_MEMORY[chat_id] = []
    
    CONVERSATION_MEMORY[chat_id].append({
        "role": role,
        "content": content,
        "timestamp": datetime.now().isoformat()
    })
    
    # mantener solo el Ãºltimo MAX_MEMORY_ENTRIES
    if len(CONVERSATION_MEMORY[chat_id]) > MAX_MEMORY_ENTRIES:
        CONVERSATION_MEMORY[chat_id] = CONVERSATION_MEMORY[chat_id][-MAX_MEMORY_ENTRIES:]
    
    save_memory()

def clear_memory(chat_id: int):
    """Clear conversation memory for a chat"""
    if chat_id in CONVERSATION_MEMORY:
        del CONVERSATION_MEMORY[chat_id]
        save_memory()

def load_whisper_model():
    """Load Whisper model on first use"""
    global WHISPER_MODEL
    if not VOICE_AVAILABLE:
        raise Exception("Voice processing not available")
    if WHISPER_MODEL is None:
        print(f"Loading Whisper model: {WHISPER_MODEL_NAME}")
        WHISPER_MODEL = whisper.load_model(WHISPER_MODEL_NAME)
        print("Whisper model loaded successfully")
    return WHISPER_MODEL

async def download_voice_file(file_id: str, file_path: str, bot_token: str):
    """Download voice file from Telegram"""
    try:
        # Get file info from Telegram
        file_info_url = f"https://api.telegram.org/bot{bot_token}/getFile?file_id={file_id}"
        response = requests.get(file_info_url)
        file_info = response.json()
        
        if not file_info.get("ok"):
            raise Exception(f"Failed to get file info: {file_info}")
        
        # Download the file
        file_url = f"https://api.telegram.org/file/bot{bot_token}/{file_info['result']['file_path']}"
        file_response = requests.get(file_url)
        
        with open(file_path, 'wb') as f:
            f.write(file_response.content)
        
        return True
    except Exception as e:
        print(f"Error downloading voice file: {e}")
        return False

def convert_audio_format(input_path: str, output_path: str):
    """Convert OGG to WAV using FFmpeg directly"""
    if not VOICE_AVAILABLE:
        raise Exception("Voice processing not available")
    try:
        # intentar con pydub primero
        audio = AudioSegment.from_file(input_path)
        audio.export(output_path, format="wav")
        return True
    except Exception as e:
        print(f"Pydub conversion failed: {e}")
        # fallback: usar FFmpeg directamente
        try:
            import subprocess
            import os
            
            # buscar FFmpeg en el directorio del proyecto
            ffmpeg_path = None
            for root, dirs, files in os.walk("."):
                if "ffmpeg.exe" in files:
                    ffmpeg_path = os.path.join(root, "ffmpeg.exe")
                    break
            
            if ffmpeg_path and os.path.exists(ffmpeg_path):
                # usar FFmpeg para convertir
                cmd = [ffmpeg_path, "-i", input_path, "-acodec", "pcm_s16le", "-ar", "16000", output_path, "-y"]
                result = subprocess.run(cmd, capture_output=True, text=True)
                if result.returncode == 0:
                    return True
                else:
                    print(f"FFmpeg conversion failed: {result.stderr}")
            
            # Ãºltimo recurso: copiar archivo directamente
            import shutil
            shutil.copy2(input_path, output_path)
            return True
            
        except Exception as e2:
            print(f"All conversion methods failed: {e2}")
            return False

def transcribe_audio(audio_path: str, language_hint: str = None):
    """Transcribe audio using multiple methods"""
    if not VOICE_AVAILABLE:
        raise Exception("Voice processing not available")
    
    # intentar con Whisper primero si estÃ¡ disponible
    try:
        model = load_whisper_model()
        
        # transcribir con detecciÃ³n de idioma
        result = model.transcribe(audio_path, language=language_hint)
        
        text = result["text"].strip()
        detected_language = result.get("language", "unknown")
        
        return text, detected_language
    except Exception as e:
        print(f"Whisper transcription failed: {e}")
        
        # fallback: intentar con Google Speech Recognition
        try:
            import speech_recognition as sr
            
            r = sr.Recognizer()
            
            # determinar idioma para Google Speech Recognition
            if language_hint:
                if language_hint.startswith('es'):
                    lang = 'es-ES'
                elif language_hint.startswith('en'):
                    lang = 'en-US'
                else:
                    lang = 'es-ES'  # por defecto a espaÃ±ol
            else:
                lang = 'es-ES'  # por defecto a espaÃ±ol
            
            with sr.AudioFile(audio_path) as source:
                audio = r.record(source)
            
            text = r.recognize_google(audio, language=lang)
            detected_language = lang
            
            return text, detected_language
            
        except Exception as e2:
            print(f"Google Speech Recognition also failed: {e2}")
            
            # Ãºltimo recurso: devolver un mensaje de placeholder
            return "No pude transcribir el audio. Por favor, intenta enviar un mensaje de texto.", "es"

# funciones de procesamiento de excel y graficos
def read_excel_file(file_source):
    """
    Read Excel file and return dataframes and sheet info with robust error handling
    Args:
        file_source: Can be a file path (str) or BytesIO object
    """
    if not EXCEL_CHARTS_AVAILABLE:
        raise Exception("Excel processing not available")
    
    try:
        # mÃºltiples intentos con diferentes motores y parÃ¡metros
        engines_to_try = ['openpyxl', 'xlrd']
        read_params = [
            {},  # parÃ¡metros por defecto
            {'na_values': ['', 'N/A', 'NULL', 'null']},  # manejar valores vacÃ­os
            {'keep_default_na': False},  # no convertir a NaN
        ]
        
        for engine in engines_to_try:
            for params in read_params:
                try:
                    # Usar context manager para asegurar que el archivo se cierre automÃ¡ticamente
                    with pd.ExcelFile(file_source, engine=engine) as excel_file:
                        sheets_info = {}
                        
                        for sheet_name in excel_file.sheet_names:
                            try:
                                # leer con los parÃ¡metros actuales
                                df = pd.read_excel(excel_file, sheet_name=sheet_name, **params)
                                
                                # limpiar el dataframe
                                df = df.dropna(how='all')  # remover filas completamente vacÃ­as
                                
                                # Limpiar columnas sin nombre solo si existen
                                unnamed_cols = [col for col in df.columns if isinstance(col, str) and col.startswith('Unnamed')]
                                if unnamed_cols:
                                    df = df.drop(columns=unnamed_cols)
                                
                                # Intentar convertir columnas a numÃ©rico cuando sea posible
                                for col in df.columns:
                                    try:
                                        # Intentar conversiÃ³n a numÃ©rico (sin el errors='ignore' deprecado)
                                        df[col] = pd.to_numeric(df[col])
                                    except (ValueError, TypeError):
                                        # Si falla, mantener la columna como estÃ¡
                                        pass
                                
                                if not df.empty:
                                    # InformaciÃ³n de columnas numÃ©ricas
                                    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
                                    print(f"Sheet '{sheet_name}': {len(numeric_cols)} numeric columns found: {numeric_cols[:5]}")
                                    
                                    sheets_info[sheet_name] = {
                                        'dataframe': df,
                                        'columns': list(df.columns),
                                        'shape': df.shape,
                                        'dtypes': df.dtypes.to_dict()
                                    }
                            except Exception as e:
                                print(f"Error reading sheet {sheet_name} with {engine}: {e}")
                                continue
                        
                        if sheets_info:
                            print(f"Successfully read Excel file using {engine} engine")
                            return sheets_info
                        
                except Exception as e:
                    print(f"Failed to read with {engine}: {e}")
                    continue
        
        # si todos los mÃ©todos fallan
        raise Exception("Could not read Excel file with any available method")
        
    except Exception as e:
        print(f"Error reading Excel file: {e}")
        return None

def get_comprehensive_data_analysis(df: pd.DataFrame) -> dict:
    """
    Realiza un anÃ¡lisis completo de un DataFrame y retorna informaciÃ³n Ãºtil
    """
    if not EXCEL_CHARTS_AVAILABLE:
        return {}
    
    try:
        analysis = {
            'total_rows': len(df),
            'total_columns': len(df.columns),
            'column_names': list(df.columns),
            'numeric_columns': [],
            'text_columns': [],
            'date_columns': [],
            'statistics': {},
            'sample_data': {},
            'data_quality': {}
        }
        
        # Analizar cada columna
        for col in df.columns:
            col_data = df[col]
            
            # Detectar tipo de columna
            if pd.api.types.is_numeric_dtype(col_data):
                analysis['numeric_columns'].append(col)
                # EstadÃ­sticas para columnas numÃ©ricas
                analysis['statistics'][col] = {
                    'count': int(col_data.count()),
                    'mean': float(col_data.mean()) if col_data.count() > 0 else 0,
                    'median': float(col_data.median()) if col_data.count() > 0 else 0,
                    'std': float(col_data.std()) if col_data.count() > 1 else 0,
                    'min': float(col_data.min()) if col_data.count() > 0 else 0,
                    'max': float(col_data.max()) if col_data.count() > 0 else 0,
                    'sum': float(col_data.sum()) if col_data.count() > 0 else 0
                }
            elif pd.api.types.is_datetime64_any_dtype(col_data):
                analysis['date_columns'].append(col)
            else:
                analysis['text_columns'].append(col)
                # Info para columnas de texto
                unique_count = col_data.nunique()
                analysis['statistics'][col] = {
                    'unique_values': int(unique_count),
                    'most_common': str(col_data.mode()[0]) if len(col_data.mode()) > 0 else 'N/A'
                }
            
            # Muestra de datos (primeros 3 valores no nulos)
            sample = col_data.dropna().head(3).tolist()
            analysis['sample_data'][col] = [str(x) for x in sample]
            
            # Calidad de datos
            null_count = col_data.isnull().sum()
            analysis['data_quality'][col] = {
                'null_count': int(null_count),
                'null_percentage': float(null_count / len(col_data) * 100) if len(col_data) > 0 else 0
            }
        
        return analysis
    
    except Exception as e:
        print(f"Error in comprehensive analysis: {e}")
        return {}

def analyze_data_for_chart(df: pd.DataFrame, chart_type: str = "auto"):
    """Analyze dataframe to determine best chart type and data"""
    if not EXCEL_CHARTS_AVAILABLE:
        raise Exception("Chart processing not available")
    
    try:
        # obtener columnas numÃ©ricas
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        analysis = {
            'numeric_columns': numeric_cols,
            'categorical_columns': categorical_cols,
            'total_rows': len(df),
            'total_cols': len(df.columns),
            'suggested_chart': chart_type
        }
        
        # sugerir tipo de grÃ¡fico automÃ¡ticamente basado en los datos
        if chart_type == "auto":
            if len(numeric_cols) >= 2:
                analysis['suggested_chart'] = "scatter"
            elif len(numeric_cols) == 1 and len(categorical_cols) >= 1:
                analysis['suggested_chart'] = "bar"
            elif len(numeric_cols) >= 1:
                analysis['suggested_chart'] = "line"
            else:
                analysis['suggested_chart'] = "bar"
        
        return analysis
    except Exception as e:
        print(f"Error analyzing data: {e}")
        return None

def create_matplotlib_chart(df: pd.DataFrame, chart_type: str, title: str = "GrÃ¡fico"):
    """Create matplotlib chart and return image bytes"""
    if not EXCEL_CHARTS_AVAILABLE:
        raise Exception("Chart processing not available")
    
    try:
        plt.figure(figsize=(12, 8))
        plt.style.use('default')
        
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if chart_type.lower() == "bar" and len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
            # grÃ¡fico de barras: categÃ³rico vs numÃ©rico
            cat_col = categorical_cols[0]
            num_col = numeric_cols[0]
            plt.bar(df[cat_col], df[num_col], color='skyblue', edgecolor='navy', alpha=0.7)
            plt.xlabel(cat_col)
            plt.ylabel(num_col)
            plt.xticks(rotation=45)
            
        elif chart_type.lower() == "line" and len(numeric_cols) >= 1:
            # grÃ¡fico de lÃ­nea
            if len(numeric_cols) >= 2:
                plt.plot(df[numeric_cols[0]], df[numeric_cols[1]], marker='o', linewidth=2, markersize=6)
                plt.xlabel(numeric_cols[0])
                plt.ylabel(numeric_cols[1])
            else:
                plt.plot(df[numeric_cols[0]], marker='o', linewidth=2, markersize=6)
                plt.xlabel('Ãndice')
                plt.ylabel(numeric_cols[0])
                
        elif chart_type.lower() == "scatter" and len(numeric_cols) >= 2:
            # grÃ¡fico de dispersiÃ³n
            plt.scatter(df[numeric_cols[0]], df[numeric_cols[1]], alpha=0.7, s=50)
            plt.xlabel(numeric_cols[0])
            plt.ylabel(numeric_cols[1])
            
        elif chart_type.lower() == "histogram" and len(numeric_cols) >= 1:
            # histograma
            plt.hist(df[numeric_cols[0]], bins=20, alpha=0.7, color='skyblue', edgecolor='navy')
            plt.xlabel(numeric_cols[0])
            plt.ylabel('Frecuencia')
            
        elif chart_type.lower() == "pie" and len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
            # grÃ¡fico de torta
            cat_col = categorical_cols[0]
            num_col = numeric_cols[0]
            plt.pie(df[num_col], labels=df[cat_col], autopct='%1.1f%%', startangle=90)
            
        else:
            # por defecto: grÃ¡fico de barras simple
            if len(numeric_cols) >= 1:
                plt.bar(range(len(df)), df[numeric_cols[0]], color='skyblue', edgecolor='navy', alpha=0.7)
                plt.xlabel('Ãndice')
                plt.ylabel(numeric_cols[0])
        
        plt.title(title, fontsize=16, fontweight='bold', pad=20)
        plt.tight_layout()
        
        # guardar en bytes
        img_buffer = io.BytesIO()
        plt.savefig(img_buffer, format='png', dpi=300, bbox_inches='tight')
        img_buffer.seek(0)
        
        plt.close()
        return img_buffer.getvalue()
        
    except Exception as e:
        print(f"Error creating matplotlib chart: {e}")
        return None

def create_plotly_chart(df: pd.DataFrame, chart_type: str, title: str = "GrÃ¡fico"):
    """Create plotly chart and return image bytes"""
    if not EXCEL_CHARTS_AVAILABLE:
        raise Exception("Chart processing not available")
    
    try:
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
        
        if chart_type.lower() == "bar" and len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
            # Bar chart
            cat_col = categorical_cols[0]
            num_col = numeric_cols[0]
            fig = px.bar(df, x=cat_col, y=num_col, title=title)
            
        elif chart_type.lower() == "line" and len(numeric_cols) >= 1:
            # Line chart
            if len(numeric_cols) >= 2:
                fig = px.line(df, x=numeric_cols[0], y=numeric_cols[1], title=title)
            else:
                fig = px.line(df, y=numeric_cols[0], title=title)
                
        elif chart_type.lower() == "scatter" and len(numeric_cols) >= 2:
            # Scatter plot
            fig = px.scatter(df, x=numeric_cols[0], y=numeric_cols[1], title=title)
            
        elif chart_type.lower() == "histogram" and len(numeric_cols) >= 1:
            # Histogram
            fig = px.histogram(df, x=numeric_cols[0], title=title)
            
        elif chart_type.lower() == "pie" and len(numeric_cols) >= 1 and len(categorical_cols) >= 1:
            # Pie chart
            cat_col = categorical_cols[0]
            num_col = numeric_cols[0]
            fig = px.pie(df, names=cat_col, values=num_col, title=title)
            
        else:
            # por defecto: grÃ¡fico de barras simple
            if len(numeric_cols) >= 1:
                fig = px.bar(df, y=numeric_cols[0], title=title)
        
        # actualizar layout
        fig.update_layout(
            font=dict(size=12),
            title_font_size=16,
            showlegend=True
        )
        
        # convertir a bytes de imagen
        img_bytes = to_image(fig, format="png", width=1200, height=800, scale=2)
        return img_bytes
        
    except Exception as e:
        print(f"Error creating plotly chart: {e}")
        return None

def detect_chart_type_from_text(text: str):
    """Detect the most appropriate chart type from user text with advanced options"""
    text_lower = text.lower()
    
    # detecciÃ³n de tipo de grÃ¡fico avanzado
    chart_mappings = {
        # Basic charts
        'pie': ['pie', 'circular', 'torta', 'pastel', 'circular', 'proporciÃ³n', 'porcentaje'],
        'bar': ['bar', 'barras', 'barra', 'columnas', 'comparar', 'comparaciÃ³n'],
        'line': ['line', 'lÃ­nea', 'linea', 'tendencia', 'evoluciÃ³n', 'tiempo', 'cronolÃ³gico'],
        'scatter': ['scatter', 'dispersiÃ³n', 'dispersion', 'puntos', 'correlaciÃ³n', 'relaciÃ³n'],
        'area': ['area', 'Ã¡rea', 'superficie', 'relleno'],
        
        # Advanced charts
        'heatmap': ['heatmap', 'calor', 'mapa_calor', 'matriz', 'tabla_calor'],
        'treemap': ['treemap', 'mapa_arbol', 'jerarquÃ­a', 'jerÃ¡rquico', 'Ã¡rbol'],
        'sunburst': ['sunburst', 'sol', 'radial', 'circular_jerarquico'],
        'funnel': ['funnel', 'embudo', 'proceso', 'conversiÃ³n', 'embudo_conversiÃ³n'],
        'waterfall': ['waterfall', 'cascada', 'puente', 'puente_financiero'],
        'sankey': ['sankey', 'flujo', 'diagrama_flujo', 'flujo_datos', 'sankey_diagram'],
        
        # Statistical charts
        'box': ['box', 'caja', 'boxplot', 'distribuciÃ³n', 'cuartiles'],
        'violin': ['violin', 'violÃ­n', 'violinplot', 'densidad'],
        'histogram': ['histogram', 'histograma', 'frecuencia', 'distribuciÃ³n_frecuencia'],
        
        # 3D and advanced visualizations
        '3d': ['3d', 'tridimensional', '3d_scatter', 'espacial'],
        'surface': ['surface', 'superficie', '3d_surface', 'terreno'],
        'contour': ['contour', 'contorno', 'curvas_nivel', 'isobaras'],
        'density': ['density', 'densidad', 'mapa_densidad', 'concentraciÃ³n'],
        
        # Polar and circular charts
        'polar': ['polar', 'polar_chart', 'coordenadas_polares'],
        'radar': ['radar', 'radar_chart', 'araÃ±a', 'web', 'estrella'],
        
        # Financial charts
        'candlestick': ['candlestick', 'vela', 'velas', 'financiero', 'bolsa'],
        'gauge': ['gauge', 'medidor', 'velocÃ­metro', 'indicador_circular'],
        'indicator': ['indicator', 'indicador', 'kpi', 'mÃ©trica'],
        
        # Flow and process charts
        'timeline': ['timeline', 'linea_tiempo', 'cronologÃ­a', 'eventos'],
        'parallel': ['parallel', 'paralelo', 'coordenadas_paralelas'],
        'icicle': ['icicle', 'carÃ¡mbano', 'rectÃ¡ngulos_jerÃ¡rquicos'],
        
        # Geographic charts
        'map': ['map', 'mapa', 'geogrÃ¡fico', 'ubicaciÃ³n', 'coordenadas'],
        'choropleth': ['choropleth', 'coropleta', 'mapa_coropleta', 'regiones'],
        
        # Bubble and advanced scatter
        'bubble': ['bubble', 'burbuja', 'bubble_chart', 'tamaÃ±o_variable']
    }
    
    # puntuar cada tipo de grÃ¡fico basado en las palabras clave encontradas
    chart_scores = {}
    for chart_type, keywords in chart_mappings.items():
        score = sum(1 for keyword in keywords if keyword in text_lower)
        if score > 0:
            chart_scores[chart_type] = score
    
    # devolver el tipo de grÃ¡fico con la puntuaciÃ³n mÃ¡s alta, o por defecto a torta
    if chart_scores:
        best_chart = max(chart_scores, key=chart_scores.get)
        return best_chart
    
    # fallback por defecto basado en las caracterÃ­sticas de los datos
    if any(word in text_lower for word in ['tiempo', 'aÃ±o', 'mes', 'dÃ­a', 'cronolÃ³gico']):
        return 'line'
    elif any(word in text_lower for word in ['comparar', 'comparaciÃ³n', 'vs', 'versus']):
        return 'bar'
    elif any(word in text_lower for word in ['proporciÃ³n', 'porcentaje', 'distribuciÃ³n']):
        return 'pie'
    elif any(word in text_lower for word in ['correlaciÃ³n', 'relaciÃ³n', 'patrÃ³n']):
        return 'scatter'
    else:
        return 'pie'  # fallback por defecto a torta

def generate_chart_from_excel(file_path: str, chart_type: str = "auto", sheet_name: str = None, title: str = None):
    """Generate chart from Excel file"""
    if not EXCEL_CHARTS_AVAILABLE:
        return None, "âŒ Funcionalidad de grÃ¡ficos no disponible. Error con las dependencias."
    
    try:
        # leer archivo Excel
        sheets_info = read_excel_file(file_path)
        if not sheets_info:
            return None, "âŒ Error leyendo el archivo Excel"
        
        # seleccionar hoja
        if sheet_name and sheet_name in sheets_info:
            selected_sheet = sheet_name
        else:
            # usar primera hoja
            selected_sheet = list(sheets_info.keys())[0]
        
        df = sheets_info[selected_sheet]['dataframe']
        
        # generar tÃ­tulo si no se proporciona
        if not title:
            title = f"GrÃ¡fico de {selected_sheet} - {chart_type.title()}"
        
        # crear grÃ¡fico (prefer plotly para mejor calidad)
        chart_bytes = create_plotly_chart(df, chart_type, title)
        if not chart_bytes:
            chart_bytes = create_matplotlib_chart(df, chart_type, title)
        
        if not chart_bytes:
            return None, "âŒ Error generando el grÃ¡fico"
        
        return chart_bytes, f"âœ… GrÃ¡fico generado desde {selected_sheet}"
        
    except Exception as e:
        return None, f"âŒ Error procesando archivo Excel: {e}"

# funciones de anÃ¡lisis matemÃ¡tico
def perform_mathematical_analysis(df: pd.DataFrame, analysis_type: str, column_name: str = None, column2_name: str = None):
    """Perform mathematical analysis on dataframe columns"""
    if not EXCEL_CHARTS_AVAILABLE:
        return None, "âŒ Funcionalidad de anÃ¡lisis matemÃ¡tico no disponible"
    
    try:
        numeric_cols = df.select_dtypes(include=['number']).columns.tolist()
        
        if not numeric_cols:
            return None, "âŒ No se encontraron columnas numÃ©ricas para anÃ¡lisis"
        
        # usar columna especificada o primera columna numÃ©rica
        if column_name and column_name in numeric_cols:
            target_col = column_name
        elif column_name and column_name in df.columns:
            return None, f"âŒ La columna '{column_name}' no es numÃ©rica. Columnas numÃ©ricas disponibles: {', '.join(numeric_cols)}"
        else:
            target_col = numeric_cols[0]
        
        if analysis_type.lower() in ['suma', 'sum', 'total']:
            result = df[target_col].sum()
            return f"ðŸ“Š **Suma de '{target_col}': {result:,.2f}**", None
            
        elif analysis_type.lower() in ['promedio', 'average', 'mean']:
            result = df[target_col].mean()
            return f"ðŸ“Š **Promedio de '{target_col}': {result:,.2f}**", None
            
        elif analysis_type.lower() in ['mediana', 'median']:
            result = df[target_col].median()
            return f"ðŸ“Š **Mediana de '{target_col}': {result:,.2f}**", None
            
        elif analysis_type.lower() in ['minimo', 'min', 'mÃ­nimo']:
            result = df[target_col].min()
            return f"ðŸ“Š **MÃ­nimo de '{target_col}': {result:,.2f}**", None
            
        elif analysis_type.lower() in ['maximo', 'max', 'mÃ¡ximo']:
            result = df[target_col].max()
            return f"ðŸ“Š **MÃ¡ximo de '{target_col}': {result:,.2f}**", None
            
        elif analysis_type.lower() in ['estadisticas', 'stats', 'estadÃ­sticas', 'descriptivo']:
            stats = df[target_col].describe()
            result = f"ðŸ“Š **EstadÃ­sticas descriptivas de '{target_col}':**\n"
            result += f"â€¢ Conteo: {stats['count']:.0f}\n"
            result += f"â€¢ Media: {stats['mean']:.2f}\n"
            result += f"â€¢ DesviaciÃ³n estÃ¡ndar: {stats['std']:.2f}\n"
            result += f"â€¢ MÃ­nimo: {stats['min']:.2f}\n"
            result += f"â€¢ 25%: {stats['25%']:.2f}\n"
            result += f"â€¢ Mediana: {stats['50%']:.2f}\n"
            result += f"â€¢ 75%: {stats['75%']:.2f}\n"
            result += f"â€¢ MÃ¡ximo: {stats['max']:.2f}"
            return result, None
            
        elif analysis_type.lower() in ['correlacion', 'correlation', 'correlaciÃ³n']:
            if column2_name and column2_name in numeric_cols:
                corr = df[target_col].corr(df[column2_name])
                return f"ðŸ“Š **CorrelaciÃ³n entre '{target_col}' y '{column2_name}': {corr:.4f}**", None
            elif len(numeric_cols) >= 2:
                # mostrar matriz de correlaciÃ³n para todas las columnas numÃ©ricas
                corr_matrix = df[numeric_cols].corr()
                result = f"ðŸ“Š **Matriz de correlaciÃ³n:**\n"
                for i, col1 in enumerate(numeric_cols):
                    for j, col2 in enumerate(numeric_cols):
                        if i < j:  # solo mostrar el triÃ¡ngulo superior
                            corr_val = corr_matrix.loc[col1, col2]
                            result += f"â€¢ {col1} â†” {col2}: {corr_val:.4f}\n"
                return result, None
            else:
                return None, "âŒ Se necesitan al menos 2 columnas numÃ©ricas para calcular correlaciÃ³n"
                
        elif analysis_type.lower() in ['conteo', 'count']:
            result = df[target_col].count()
            return f"ðŸ“Š **Conteo de '{target_col}': {result} valores no nulos**", None
            
        elif analysis_type.lower() in ['desviacion', 'std', 'desviaciÃ³n']:
            result = df[target_col].std()
            return f"ðŸ“Š **DesviaciÃ³n estÃ¡ndar de '{target_col}': {result:.2f}**", None
            
        elif analysis_type.lower() in ['varianza', 'variance']:
            result = df[target_col].var()
            return f"ðŸ“Š **Varianza de '{target_col}': {result:.2f}**", None
            
        else:
            return None, f"âŒ Tipo de anÃ¡lisis '{analysis_type}' no reconocido. Tipos disponibles: suma, promedio, mediana, mÃ­nimo, mÃ¡ximo, estadÃ­sticas, correlaciÃ³n, conteo, desviaciÃ³n, varianza"
            
    except Exception as e:
        return None, f"âŒ Error en anÃ¡lisis matemÃ¡tico: {e}"

def detect_mathematical_request(text: str):
    """Detect if user is requesting mathematical analysis"""
    text_lower = text.lower()
    
    math_keywords = [
        'suma', 'sum', 'total', 'sumar',
        'promedio', 'average', 'mean', 'media',
        'mediana', 'median',
        'minimo', 'min', 'mÃ­nimo', 'menor',
        'maximo', 'max', 'mÃ¡ximo', 'mayor',
        'estadisticas', 'stats', 'estadÃ­sticas', 'descriptivo',
        'correlacion', 'correlation', 'correlaciÃ³n',
        'conteo', 'count', 'contar',
        'desviacion', 'std', 'desviaciÃ³n',
        'varianza', 'variance',
        'calcula', 'calculate', 'calcular',
        'analiza', 'analyze', 'anÃ¡lisis'
    ]
    
    return any(keyword in text_lower for keyword in math_keywords)

def extract_column_names(text: str, available_columns: list):
    """Extract column names from user text"""
    text_lower = text.lower()
    found_columns = []
    
    for col in available_columns:
        col_lower = col.lower()
        if col_lower in text_lower or col in text:
            found_columns.append(col)
    
    return found_columns

def extract_data_from_text(text: str):
    """Extract numerical data and categories from descriptive text"""
    import re
    
    # patrones comunes para la extracciÃ³n de datos
    patterns = [
        # Pattern: "X personas, Y de ellas..."
        r'(\d+)\s*(?:personas?|gente|individuos?|elementos?)',
        # Pattern: "X de ellas cumplen en Y"
        r'(\d+)\s*(?:de ellas|de los|de las)?\s*(?:cumplen|nacen|estÃ¡n|son|tienen|pertenecen)\s*(?:en|a|del|de)\s*([^,\n]+)',
        # Pattern: "X en Y"
        r'(\d+)\s*(?:en|de|del|para)\s*([^,\n]+)',
        # Pattern: "Y: X"
        r'([^:\d]+):\s*(\d+)',
        # Pattern: "X Y" (number followed by category)
        r'(\d+)\s+([a-zA-ZÃ¡Ã©Ã­Ã³ÃºÃ±Ã¼ÃÃ‰ÃÃ“ÃšÃ‘Ãœ\s]+?)(?:\s*,\s*|\s*\.\s*|\s*$|\s*y\s*)',
    ]
    
    extracted_data = {}
    text_lower = text.lower()
    
    # Look for total count
    total_match = re.search(r'(\d+)\s*(?:personas?|gente|individuos?|elementos?|total)', text_lower)
    total_count = int(total_match.group(1)) if total_match else None
    
    # extraer categorÃ­as y sus conteos  
    for pattern in patterns:
        matches = re.findall(pattern, text_lower)
        for match in matches:
            if len(match) == 2:
                count_str, category = match
                try:
                    count = int(count_str.strip())
                    category = category.strip()
                    
                    # limpiar nombre de categorÃ­a
                    category = re.sub(r'\s+', ' ', category)  # remover espacios extra  
                    category = category.strip('.,;:')  # remover puntuaciÃ³n
                    
                    if category and count > 0:
                        extracted_data[category] = count
                except ValueError:
                    continue
    
    # si tenemos un total, calcular "otros" o el resto
    if total_count and extracted_data:
        calculated_total = sum(extracted_data.values())
        if calculated_total < total_count:
            remaining = total_count - calculated_total
            if remaining > 0:
                extracted_data['Otros'] = remaining
    
    return extracted_data, total_count

def create_chart_from_text_data(data: dict, chart_type: str = "pie", title: str = "GrÃ¡fico de Datos"):
    """Create a chart from extracted text data with advanced chart types"""
    if not EXCEL_CHARTS_AVAILABLE:
        return None, "âŒ Funcionalidad de grÃ¡ficos no disponible"
    
    try:
        if not data:
            return None, "âŒ No se pudieron extraer datos del texto"
        
        # convertir a pandas DataFrame
        df = pd.DataFrame(list(data.items()), columns=['CategorÃ­a', 'Valor'])
        
        # crear grÃ¡fico basado en el tipo
        chart_type_lower = chart_type.lower()
        
        if chart_type_lower in ['pie', 'circular', 'torta', 'pastel']:
            fig = px.pie(df, values='Valor', names='CategorÃ­a', title=title)
            fig.update_traces(textposition='inside', textinfo='percent+label')
            
        elif chart_type_lower in ['bar', 'barras', 'barra']:
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=title)
            fig.update_layout(xaxis_tickangle=-45)
            
        elif chart_type_lower in ['column', 'columna']:
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=title, orientation='v')
            
        elif chart_type_lower in ['line', 'lÃ­nea', 'linea', 'tendencia']:
            fig = px.line(df, x='CategorÃ­a', y='Valor', title=title, markers=True)
            
        elif chart_type_lower in ['scatter', 'dispersiÃ³n', 'dispersion', 'puntos']:
            fig = px.scatter(df, x='CategorÃ­a', y='Valor', title=title, size='Valor')
            
        elif chart_type_lower in ['area', 'Ã¡rea', 'area_chart']:
            fig = px.area(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['funnel', 'embudo', 'embudo']:
            fig = px.funnel(df, x='Valor', y='CategorÃ­a', title=title)
            
        elif chart_type_lower in ['sunburst', 'sol', 'sunburst_chart']:
            # crear datos jerÃ¡rquicos para sunburst
            fig = px.sunburst(df, path=['CategorÃ­a'], values='Valor', title=title)
            
        elif chart_type_lower in ['treemap', 'mapa_arbol', 'treemap_chart']:
            fig = px.treemap(df, path=['CategorÃ­a'], values='Valor', title=title)
            
        elif chart_type_lower in ['waterfall', 'cascada', 'waterfall_chart']:
            fig = px.waterfall(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['box', 'caja', 'boxplot']:
            fig = px.box(df, y='Valor', title=title)
            
        elif chart_type_lower in ['violin', 'violÃ­n', 'violinplot']:
            fig = px.violin(df, y='Valor', title=title)
            
        elif chart_type_lower in ['histogram', 'histograma']:
            fig = px.histogram(df, x='Valor', title=title)
            
        elif chart_type_lower in ['heatmap', 'calor', 'mapa_calor']:
            # crear datos de mapa de calor
            heatmap_data = df.pivot_table(values='Valor', index='CategorÃ­a', columns='CategorÃ­a', fill_value=0)
            fig = px.imshow(heatmap_data, title=title, color_continuous_scale='Viridis')
            
        elif chart_type_lower in ['polar', 'polar_chart']:
            fig = px.bar_polar(df, r='Valor', theta='CategorÃ­a', title=title)
            
        elif chart_type_lower in ['radar', 'radar_chart']:
            fig = px.line_polar(df, r='Valor', theta='CategorÃ­a', line_close=True, title=title)
            
        elif chart_type_lower in ['sankey', 'sankey_diagram']:
            # crear diagrama de Sankey usando go.Sankey
            import plotly.graph_objects as go
            
            # crear datos de flujo simple
            sources = [0, 1, 2] if len(df) >= 3 else list(range(len(df)))
            targets = [len(df)] * len(sources)
            values = df['Valor'].tolist()
            labels = df['CategorÃ­a'].tolist() + ['Proceso Central']
            
            fig = go.Figure(data=[go.Sankey(
                node=dict(
                    pad=15,
                    thickness=20,
                    line=dict(color="black", width=0.5),
                    label=labels,
                    color="lightblue"
                ),
                link=dict(
                    source=sources,
                    target=targets,
                    value=values
                )
            )])
            fig.update_layout(title_text=title)
            
        elif chart_type_lower in ['candlestick', 'vela', 'candlestick_chart']:
            # crear grÃ¡fico de velas usando go.Candlestick
            import plotly.graph_objects as go
            
            # crear datos sintÃ©ticos OHLC
            fig = go.Figure(data=[go.Candlestick(
                x=df['CategorÃ­a'],
                open=df['Valor'] * 0.95,
                high=df['Valor'] * 1.05,
                low=df['Valor'] * 0.9,
                close=df['Valor']
            )])
            fig.update_layout(title_text=title)
            
        elif chart_type_lower in ['density', 'densidad', 'density_chart']:
            # crear mapa de calor de densidad
            fig = px.imshow([[df['Valor'].iloc[i] for i in range(len(df))]], title=title, color_continuous_scale='Viridis')
            
        elif chart_type_lower in ['contour', 'contorno', 'contour_chart']:
                # crear grÃ¡fico de contorno
            fig = px.density_contour(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['surface', 'superficie', 'surface_chart']:
            # crear grÃ¡fico de superficie 3D
            fig = px.scatter_3d(df, x='CategorÃ­a', y='Valor', z='Valor', title=title)
            
        elif chart_type_lower in ['3d', '3d_scatter', 'tridimensional']:
            fig = px.scatter_3d(df, x='CategorÃ­a', y='Valor', z='Valor', title=title)
            
        elif chart_type_lower in ['bubble', 'burbuja', 'bubble_chart']:
            fig = px.scatter(df, x='CategorÃ­a', y='Valor', size='Valor', title=title)
            
        elif chart_type_lower in ['gauge', 'medidor', 'gauge_chart']:
            # crear grÃ¡fico de medidor usando go.Indicator
            import plotly.graph_objects as go
            
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=df['Valor'].sum(),
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': title},
                gauge={'axis': {'range': [None, df['Valor'].max() * 1.2]},
                       'bar': {'color': "darkblue"},
                       'steps': [
                           {'range': [0, df['Valor'].max() * 0.5], 'color': "lightgray"},
                           {'range': [df['Valor'].max() * 0.5, df['Valor'].max()], 'color': "gray"}],
                       'threshold': {'line': {'color': "red", 'width': 4},
                                   'thickness': 0.75, 'value': df['Valor'].max() * 0.9}}))
            
        elif chart_type_lower in ['indicator', 'indicador', 'indicator_chart']:
            # crear grÃ¡fico de indicador usando go.Indicator
            import plotly.graph_objects as go
            
            fig = go.Figure(go.Indicator(
                mode="number+delta",
                value=df['Valor'].sum(),
                title={'text': title},
                delta={'reference': df['Valor'].mean()}
            ))
            
        elif chart_type_lower in ['icicle', 'carÃ¡mbano', 'icicle_chart']:
            # crear grÃ¡fico de carÃ¡mbano (fallback a treemap)
            fig = px.treemap(df, path=['CategorÃ­a'], values='Valor', title=title)
            
        elif chart_type_lower in ['parallel', 'paralelo', 'parallel_chart']:
            # crear coordenadas paralelas (fallback a grÃ¡fico de lÃ­nea)
            fig = px.line(df, x='CategorÃ­a', y='Valor', title=title, markers=True)
            
        elif chart_type_lower in ['parallel_categories', 'categorias_paralelas']:
            # crear categorÃ­as paralelas (fallback a grÃ¡fico de barras)
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['timeline', 'linea_tiempo', 'timeline_chart']:
            # crear lÃ­nea de tiempo (fallback a grÃ¡fico de barras)
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['map', 'mapa', 'map_chart']:
            # crear mapa (fallback a grÃ¡fico de dispersiÃ³n)
            fig = px.scatter(df, x='CategorÃ­a', y='Valor', title=title)
            
        elif chart_type_lower in ['choropleth', 'coropleta', 'choropleth_chart']:
            # crear choropleth (fallback a grÃ¡fico de barras)
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=title)
            
        else:
            # por defecto: grÃ¡fico de torta
            fig = px.pie(df, values='Valor', names='CategorÃ­a', title=title)
            fig.update_traces(textposition='inside', textinfo='percent+label')
        
        # personalizar layout
        fig.update_layout(
            title_font_size=16,
            font_size=12,
            showlegend=True,
            height=600,
            width=800
        )
        
        # convertir a bytes de imagen
        chart_bytes = fig.to_image(format="png", width=800, height=600, scale=2)
        
        return chart_bytes, f"âœ… GrÃ¡fico {chart_type} generado desde texto"
        
    except Exception as e:
        return None, f"âŒ Error generando grÃ¡fico {chart_type}: {e}"

def detect_chart_request_from_text(text: str):
    """Detect if user is requesting a chart from descriptive text"""
    text_lower = text.lower()
    
    # palabras clave que indican solicitud de grÃ¡fico
    chart_keywords = [
        'grÃ¡fico', 'grafico', 'grÃ¡fica', 'grafica', 'chart', 'diagrama',
        'crea', 'crear', 'genera', 'generar', 'haz', 'hacer',
        'muestra', 'mostrar', 'visualiza', 'visualizar',
        'personas', 'gente', 'individuos', 'elementos',
        'cumplen', 'nacen', 'estÃ¡n', 'pertenecen'
    ]
    
    # verificar patrones de datos numÃ©ricos
    import re
    has_numbers = bool(re.search(r'\d+', text))
    has_categories = any(word in text_lower for word in ['diciembre', 'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'mes', 'aÃ±o', 'dÃ­a'])
    
    return any(keyword in text_lower for keyword in chart_keywords) and has_numbers and has_categories

# funciones de anÃ¡lisis de datos avanzado y procesamiento
def analyze_data_with_gemini(text_data: str, chat_id: int, api_url: str, api_key: str):
    """Use Gemini to analyze and structure data for better chart generation"""
    try:
        # primero intentar un anÃ¡lisis simple sin Gemini
        simple_analysis = simple_data_analysis(text_data)
        if simple_analysis:
            return simple_analysis
        
        # si el anÃ¡lisis simple falla, intentar con Gemini
        analysis_prompt = f"""
Analiza los siguientes datos y proporciona un anÃ¡lisis estructurado:

DATOS: {text_data}

Por favor proporciona:
1. TIPO DE DATOS: Â¿QuÃ© tipo de informaciÃ³n contienen estos datos?
2. CATEGORÃAS IDENTIFICADAS: Lista las categorÃ­as principales encontradas
3. VALORES NUMÃ‰RICOS: Extrae todos los nÃºmeros y sus categorÃ­as correspondientes. Si hay porcentajes solicitados, calcÃºlalos.
4. TIPO DE GRÃFICO RECOMENDADO: Â¿QuÃ© tipo de grÃ¡fico serÃ­a mÃ¡s apropiado?
5. TÃTULO SUGERIDO: PropÃ³n un tÃ­tulo descriptivo para el grÃ¡fico
6. ANÃLISIS: Â¿QuÃ© patrones o tendencias observas? Incluye cÃ¡lculos de porcentajes si se solicitan.

IMPORTANTE: Si se solicitan porcentajes, calcÃºlalos correctamente. Por ejemplo:
- Si hay 50 personas totales y 33 son niÃ±os: niÃ±os = 33/50 = 66%, niÃ±as = 17/50 = 34%

Formato de respuesta:
TIPO: [tipo de datos]
CATEGORÃAS: [lista de categorÃ­as]
VALORES: [categorÃ­a: valor, categorÃ­a: valor, ...]
GRÃFICO: [tipo recomendado]
TÃTULO: [tÃ­tulo sugerido]
ANÃLISIS: [anÃ¡lisis de patrones con cÃ¡lculos de porcentajes]
"""
        
        # usar solicitud HTTP sincrÃ³nica en lugar de funciÃ³n asÃ­ncrona
        import requests
        import json
        
        headers = {
            "Content-Type": "application/json",
        }
        
        # preparar payload basado en el formato de URL de la API
        if "generateContent" in api_url:
            payload = {
                "contents": [
                    {
                        "parts": [
                            {"text": analysis_prompt}
                        ]
                    }
                ]
            }
        else:
            payload = {
                "instances": [
                    {
                        "content": analysis_prompt
                    }
                ]
            }
        
        # hacer solicitud sincrÃ³nica
        response = requests.post(
            f"{api_url}?key={api_key}",
            headers=headers,
            json=payload,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            
            # parsear respuesta basado en el formato de API
            if "candidates" in result and len(result["candidates"]) > 0:
                if "content" in result["candidates"][0] and "parts" in result["candidates"][0]["content"]:
                    response_text = result["candidates"][0]["content"]["parts"][0]["text"]
                else:
                    response_text = str(result["candidates"][0])
            elif "predictions" in result and len(result["predictions"]) > 0:
                response_text = str(result["predictions"][0])
            else:
                response_text = str(result)
            
            return parse_gemini_analysis(response_text)
        else:
            print(f"Error calling Gemini: Request failed with status {response.status_code}: {response.text}")
            return None
        
    except Exception as e:
        print(f"Error analyzing data with Gemini: {e}")
        return None

def simple_data_analysis(text_data: str):
    """Simple data analysis without Gemini for basic cases"""
    try:
        import re
        
        # buscar patrones comunes
        text_lower = text_data.lower()
        
        # patrÃ³n 1: "Hay X personas, Y son A y el resto son B"
        pattern1 = r'hay\s+(\d+)\s+(\w+),\s*(\d+)\s+son\s+(\w+)\s+y\s+el\s+resto\s+son\s+(\w+)'
        match1 = re.search(pattern1, text_lower)
        
        if match1:
            total = int(match1.group(1))
            category1_count = int(match1.group(3))
            category1_name = match1.group(4)
            category2_name = match1.group(5)
            category2_count = total - category1_count
            
            # calcular porcentajes
            cat1_percent = (category1_count / total) * 100
            cat2_percent = (category2_count / total) * 100
            
            analysis = {
                'data_type': 'DistribuciÃ³n demogrÃ¡fica',
                'categories': [category1_name, category2_name],
                'values': {
                    category1_name: category1_count,
                    category2_name: category2_count
                },
                'chart_type': 'pie',
                'title': f'DistribuciÃ³n de {category1_name} y {category2_name}',
                'analysis': f'De las {total} personas totales:\n- {category1_name}: {category1_count} personas ({cat1_percent:.1f}%)\n- {category2_name}: {category2_count} personas ({cat2_percent:.1f}%)'
            }
            return analysis
        
        # patrÃ³n 2: "X personas, Y son A y Z son B"
        pattern2 = r'(\d+)\s+(\w+),\s*(\d+)\s+son\s+(\w+)\s+y\s+(\d+)\s+son\s+(\w+)'
        match2 = re.search(pattern2, text_lower)
        
        if match2:
            total = int(match2.group(1))
            category1_count = int(match2.group(3))
            category1_name = match2.group(4)
            category2_count = int(match2.group(5))
            category2_name = match2.group(6)
            
            # calcular porcentajes
            cat1_percent = (category1_count / total) * 100
            cat2_percent = (category2_count / total) * 100
            
            analysis = {
                'data_type': 'DistribuciÃ³n demogrÃ¡fica',
                'categories': [category1_name, category2_name],
                'values': {
                    category1_name: category1_count,
                    category2_name: category2_count
                },
                'chart_type': 'pie',
                'title': f'DistribuciÃ³n de {category1_name} y {category2_name}',
                'analysis': f'De las {total} personas totales:\n- {category1_name}: {category1_count} personas ({cat1_percent:.1f}%)\n- {category2_name}: {category2_count} personas ({cat2_percent:.1f}%)'
            }
            return analysis
        
        # patrÃ³n 3: "X son A y Y son B"
        pattern3 = r'(\d+)\s+son\s+(\w+)\s+y\s+(\d+)\s+son\s+(\w+)'
        match3 = re.search(pattern3, text_lower)
        
        if match3:
            category1_count = int(match3.group(1))
            category1_name = match3.group(2)
            category2_count = int(match3.group(3))
            category2_name = match3.group(4)
            total = category1_count + category2_count
            
            # calcular porcentajes
            cat1_percent = (category1_count / total) * 100
            cat2_percent = (category2_count / total) * 100
            
            analysis = {
                'data_type': 'DistribuciÃ³n demogrÃ¡fica',
                'categories': [category1_name, category2_name],
                'values': {
                    category1_name: category1_count,
                    category2_name: category2_count
                },
                'chart_type': 'pie',
                'title': f'DistribuciÃ³n de {category1_name} y {category2_name}',
                'analysis': f'Total: {total} personas\n- {category1_name}: {category1_count} personas ({cat1_percent:.1f}%)\n- {category2_name}: {category2_count} personas ({cat2_percent:.1f}%)'
            }
            return analysis
        
        return None
        
    except Exception as e:
        print(f"Error in simple data analysis: {e}")
        return None

def parse_gemini_analysis(response: str):
    """Parse Gemini's structured analysis response"""
    try:
        analysis = {
            'data_type': 'Datos generales',
            'categories': [],
            'values': {},
            'chart_type': 'pie',
            'title': 'GrÃ¡fico de Datos',
            'analysis': 'AnÃ¡lisis no disponible'
        }
        
        # depuraciÃ³n: imprimir la respuesta para ver quÃ© obtenemos
        print(f"Gemini response: {response}")
        
        lines = response.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('TIPO:'):
                analysis['data_type'] = line.replace('TIPO:', '').strip()
            elif line.startswith('CATEGORÃAS:'):
                categories_text = line.replace('CATEGORÃAS:', '').strip()
                analysis['categories'] = [cat.strip() for cat in categories_text.split(',') if cat.strip()]
            elif line.startswith('VALORES:'):
                values_text = line.replace('VALORES:', '').strip()
                for pair in values_text.split(','):
                    if ':' in pair:
                        cat, val = pair.split(':', 1)
                        try:
                            # extraer valor numÃ©rico del texto
                            import re
                            numbers = re.findall(r'\d+\.?\d*', val.strip())
                            if numbers:
                                analysis['values'][cat.strip()] = float(numbers[0])
                        except ValueError:
                            continue
            elif line.startswith('GRÃFICO:'):
                chart_type = line.replace('GRÃFICO:', '').strip().lower()
                if 'barras' in chart_type or 'bar' in chart_type:
                    analysis['chart_type'] = 'bar'
                elif 'circular' in chart_type or 'pie' in chart_type:
                    analysis['chart_type'] = 'pie'
                else:
                    analysis['chart_type'] = 'pie'
            elif line.startswith('TÃTULO:'):
                analysis['title'] = line.replace('TÃTULO:', '').strip()
            elif line.startswith('ANÃLISIS:'):
                analysis['analysis'] = line.replace('ANÃLISIS:', '').strip()
        
        # si no se extrajeron valores, intentar extraerlos del texto de anÃ¡lisis
        if not analysis['values']:
            import re
            # Look for patterns like "33 niÃ±os", "17 niÃ±as", etc.
            numbers = re.findall(r'(\d+)\s+(\w+)', response)
            for number, category in numbers:
                analysis['values'][category] = float(number)
        
        # si aÃºn no se extrajeron valores, intentar extraerlos del texto original
        if not analysis['values']:
            import re
            # buscar patrones como "33 son niÃ±os", "17 son niÃ±as", etc.
            patterns = [
                r'(\d+)\s+son\s+(\w+)',
                r'(\d+)\s+(\w+)',
                r'(\d+)\s+de\s+ellas\s+(\w+)',
                r'(\d+)\s+(\w+)\s+y\s+(\d+)\s+(\w+)'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, response, re.IGNORECASE)
                for match in matches:
                    if len(match) == 2:
                        number, category = match
                        analysis['values'][category] = float(number)
                    elif len(match) == 4:
                        # manejar patrÃ³n "X niÃ±os y Y niÃ±as"
                        num1, cat1, num2, cat2 = match
                        analysis['values'][cat1] = float(num1)
                        analysis['values'][cat2] = float(num2)
        
        print(f"Parsed analysis: {analysis}")
        return analysis
        
    except Exception as e:
        print(f"Error parsing Gemini analysis: {e}")
        return None

def store_analyzed_data(chat_id: int, data_type: str, categories: list, values: dict, analysis: str, chart_type: str = "pie", title: str = "GrÃ¡fico de Datos"):
    """Store analyzed data in user's context for future reference"""
    try:
        # cargar almacenamiento de datos existente
        storage_file = f"user_data_{chat_id}.json"
        if os.path.exists(storage_file):
            with open(storage_file, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
        else:
            user_data = {'datasets': [], 'analyses': []}
        
        # agregar nuevo conjunto de datos
        dataset = {
            'timestamp': datetime.now().isoformat(),
            'data_type': data_type,
            'categories': categories,
            'values': values,
            'analysis': analysis,
            'chart_type': chart_type,
            'title': title
        }
        
        user_data['datasets'].append(dataset)
        
        # mantener solo los Ãºltimos 10 conjuntos de datos
        if len(user_data['datasets']) > 10:
            user_data['datasets'] = user_data['datasets'][-10:]
        
        # guardar datos actualizados
        with open(storage_file, 'w', encoding='utf-8') as f:
            json.dump(user_data, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        print(f"Error storing analyzed data: {e}")
        return False

def get_last_analyzed_data(chat_id: int):
    """Get the last analyzed data for a user"""
    try:
        storage_file = f"user_data_{chat_id}.json"
        if os.path.exists(storage_file):
            with open(storage_file, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
                datasets = user_data.get('datasets', [])
                if datasets:
                    return datasets[-1]  # devolver Ãºltimo conjunto de datos
        return None
    except Exception as e:
        print(f"Error getting last analyzed data: {e}")
        return None

def get_stored_datasets(chat_id: int):
    """Retrieve stored datasets for user"""
    try:
        storage_file = f"user_data_{chat_id}.json"
        if os.path.exists(storage_file):
            with open(storage_file, 'r', encoding='utf-8') as f:
                user_data = json.load(f)
                return user_data.get('datasets', [])
        return []
    except Exception as e:
        print(f"Error retrieving stored datasets: {e}")
        return []

def create_flow_diagram(data: dict, title: str = "Diagrama de Flujo"):
    """Create a flow diagram using Sankey or flow visualization"""
    if not EXCEL_CHARTS_AVAILABLE:
        return None, "âŒ Funcionalidad de grÃ¡ficos no disponible"
    
    try:
        import plotly.graph_objects as go
        
        # convertir datos a formato de flujo
        categories = list(data.keys())
        values = list(data.values())
        
        # crear datos de flujo para Sankey
        sources = []
        targets = []
        values_flow = []
        
        # crear un flujo simple desde cada categorÃ­a a un nodo central
        for i, (category, value) in enumerate(data.items()):
            sources.append(i)
            targets.append(len(categories))  # nodo central
            values_flow.append(value)
        
        # agregar etiquetas
        labels = categories + ['Proceso Central']
        
        # crear diagrama de Sankey usando go.Sankey
        fig = go.Figure(data=[go.Sankey(
            node=dict(
                pad=15,
                thickness=20,
                line=dict(color="black", width=0.5),
                label=labels,
                color="blue"
            ),
            link=dict(
                source=sources,
                target=targets,
                value=values_flow
            )
        )])
        
        fig.update_layout(
            title_text=title,
            title_font_size=16,
            font_size=12,
            height=600,
            width=800
        )
        
        chart_bytes = fig.to_image(format="png", width=800, height=600, scale=2)
        return chart_bytes, f"âœ… Diagrama de flujo generado"
        
    except Exception as e:
        return None, f"âŒ Error generando diagrama de flujo: {e}"

def create_advanced_analysis(data: dict, analysis_type: str, title: str = "AnÃ¡lisis Avanzado"):
    """Create advanced statistical analysis and visualizations"""
    if not EXCEL_CHARTS_AVAILABLE:
        return None, "âŒ Funcionalidad de grÃ¡ficos no disponible"
    
    try:
        df = pd.DataFrame(list(data.items()), columns=['CategorÃ­a', 'Valor'])
        
        if analysis_type == 'correlation_matrix':
            # crear matriz de correlaciÃ³n
            corr_data = df.pivot_table(values='Valor', index='CategorÃ­a', columns='CategorÃ­a', fill_value=0)
            fig = px.imshow(corr_data, title=f"{title} - Matriz de CorrelaciÃ³n", color_continuous_scale='RdBu')
            
        elif analysis_type == 'distribution_analysis':
            # crear anÃ¡lisis de distribuciÃ³n
            fig = px.histogram(df, x='Valor', title=f"{title} - AnÃ¡lisis de DistribuciÃ³n", nbins=10)
            
        elif analysis_type == 'outlier_detection':
            # crear grÃ¡fico de caja para detecciÃ³n de outliers
            fig = px.box(df, y='Valor', title=f"{title} - DetecciÃ³n de Outliers")
            
        elif analysis_type == 'trend_analysis':
            # crear anÃ¡lisis de tendencia
            fig = px.line(df, x='CategorÃ­a', y='Valor', title=f"{title} - AnÃ¡lisis de Tendencia", markers=True)
            
        elif analysis_type == 'comparative_analysis':
            # crear anÃ¡lisis comparativo
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=f"{title} - AnÃ¡lisis Comparativo")
            
        else:
            # por defecto: grÃ¡fico de torta
            fig = px.pie(df, values='Valor', names='CategorÃ­a', title=f"{title} - AnÃ¡lisis General")
        
        fig.update_layout(
            title_font_size=16,
            font_size=12,
            height=600,
            width=800
        )
        
        chart_bytes = fig.to_image(format="png", width=800, height=600, scale=2)
        return chart_bytes, f"âœ… AnÃ¡lisis {analysis_type} generado"
        
    except Exception as e:
        return None, f"âŒ Error generando anÃ¡lisis {analysis_type}: {e}"

def detect_analysis_type_from_text(text: str):
    """Detect the type of analysis requested from user text"""
    text_lower = text.lower()
    
    analysis_mappings = {
        'correlation_matrix': ['correlaciÃ³n', 'matriz', 'relaciÃ³n', 'correlacion'],
        'distribution_analysis': ['distribuciÃ³n', 'distribucion', 'frecuencia', 'histograma'],
        'outlier_detection': ['outliers', 'valores_atÃ­picos', 'anÃ³malos', 'extremos'],
        'trend_analysis': ['tendencia', 'evoluciÃ³n', 'cambio', 'progresiÃ³n'],
        'comparative_analysis': ['comparar', 'comparaciÃ³n', 'vs', 'versus'],
        'flow_diagram': ['flujo', 'proceso', 'diagrama_flujo', 'sankey'],
        'heatmap': ['calor', 'mapa_calor', 'heatmap', 'matriz'],
        'treemap': ['jerarquÃ­a', 'jerarquico', 'Ã¡rbol', 'treemap'],
        'sunburst': ['radial', 'sol', 'sunburst', 'circular_jerarquico']
    }
    
    for analysis_type, keywords in analysis_mappings.items():
        if any(keyword in text_lower for keyword in keywords):
            return analysis_type
    
    return 'comparative_analysis'  # Default

def enhance_chart_with_analysis(chart_bytes: bytes, analysis: dict, extracted_data: dict):
    """Enhance chart with analysis insights"""
    if not EXCEL_CHARTS_AVAILABLE:
        return chart_bytes
    
    try:
        # convertir bytes de imagen a DataFrame para mejorar
        df = pd.DataFrame(list(extracted_data.items()), columns=['CategorÃ­a', 'Valor'])
        
        # crear grÃ¡fico mejorado con anÃ¡lisis
        if analysis['chart_type'] == 'pie':
            fig = px.pie(df, values='Valor', names='CategorÃ­a', title=analysis['title'])
            fig.update_traces(textposition='inside', textinfo='percent+label')
        else:
            fig = px.bar(df, x='CategorÃ­a', y='Valor', title=analysis['title'])
            fig.update_layout(xaxis_tickangle=-45)
        
        # agregar anÃ¡lisis como anotaciÃ³n
        if analysis['analysis'] and analysis['analysis'] != 'AnÃ¡lisis no disponible':
            fig.add_annotation(
                text=f"AnÃ¡lisis: {analysis['analysis']}",
                xref="paper", yref="paper",
                x=0.5, y=-0.15,
                showarrow=False,
                font=dict(size=10, color="gray"),
                align="center"
            )
        
        # layout mejorado
        fig.update_layout(
            title_font_size=16,
            font_size=12,
            showlegend=True,
            height=600,  # aumentar altura para anÃ¡lisis
            width=800,   # aumentar ancho
            margin=dict(b=100)  # margen inferior para texto de anÃ¡lisis
        )
        
        # convertir de nuevo a bytes de imagen
        enhanced_bytes = fig.to_image(format="png", width=800, height=600, scale=2)
        return enhanced_bytes
        
    except Exception as e:
        print(f"Error enhancing chart: {e}")
        return chart_bytes

def generate_audio_response(text: str, language: str = "es"):
    """Generate audio response using gTTS"""
    if not VOICE_AVAILABLE:
        raise Exception("Voice processing not available")
    try:
        # mapear cÃ³digos de idioma
        lang_map = {
            "es": "es",  # Spanish
            "en": "en",  # English
            "spanish": "es",
            "english": "en"
        }
        
        gtts_lang = lang_map.get(language.lower(), "es")
        
        # generar audio
        tts = gTTS(text=text, lang=gtts_lang, slow=False)
        
        # guardar en archivo temporal
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(temp_file.name)
        
        return temp_file.name
    except Exception as e:
        print(f"Error generating audio response: {e}")
        return None

# comando /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    add_to_memory(chat_id, "system", "Bot started")
    await update.message.reply_text("Â¡Hola! Soy tu bot de Telegram con memoria. Puedo recordar nuestra conversaciÃ³n. Usa /help para ver comandos disponibles.")


# comando /help
async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = (
        "Comandos disponibles:\n"
        "/start - Comienza la conversaciÃ³n\n"
        "/help - Mostrar esta ayuda\n"
        "/echo <texto> - El bot devuelve el texto provisto\n"
        "/clear - Limpiar historial de conversaciÃ³n\n"
        "/memory - Ver historial de conversaciÃ³n\n"
        "/audiolimit - Ver lÃ­mite actual de caracteres para audio\n"
        "/setaudiolimit <nÃºmero> - Cambiar lÃ­mite de caracteres para audio\n"
        "/charthelp - Ayuda para generaciÃ³n de grÃ¡ficos\n"
        "/analyze [datos] - Analizar datos con IA sin generar grÃ¡fico\n"
        "/creargrafica - Crear grÃ¡fico basado en anÃ¡lisis previo\n"
        "/datahistory - Ver historial de anÃ¡lisis de datos\n"
        "/cleardata - Limpiar historial de datos\n"
        "ðŸŽ¤ EnvÃ­a un mensaje de voz y recibirÃ¡s transcripciÃ³n + respuesta en audio" if VOICE_AVAILABLE else "ðŸŽ¤ Funcionalidad de voz temporalmente deshabilitada" + "\n"
        "ðŸ“Š EnvÃ­a un archivo Excel (.xlsx) para generar grÃ¡ficos y anÃ¡lisis matemÃ¡ticos" if EXCEL_CHARTS_AVAILABLE else "ðŸ“Š Funcionalidad de Excel temporalmente deshabilitada" + "\n"
        "ðŸ“ˆ Escribe datos descriptivos para generar grÃ¡ficos automÃ¡ticamente" if EXCEL_CHARTS_AVAILABLE else ""
    )
    await update.message.reply_text(help_text)

async def chart_help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show help for chart generation functionality"""
    if not EXCEL_CHARTS_AVAILABLE:
        await update.message.reply_text("âŒ Funcionalidad de grÃ¡ficos no disponible.")
        return
    
    help_text = """
ðŸ“Š **GeneraciÃ³n de GrÃ¡ficos y AnÃ¡lisis MatemÃ¡tico Avanzado**

**ðŸ§  AnÃ¡lisis Inteligente con IA:**
â€¢ Gemini analiza automÃ¡ticamente tus datos
â€¢ Identifica patrones y tendencias
â€¢ Recomienda el mejor tipo de grÃ¡fico
â€¢ Genera tÃ­tulos descriptivos
â€¢ Almacena anÃ¡lisis para referencia futura

**ðŸ“ˆ Comandos Disponibles:**
â€¢ `/analyze [datos]` - Analizar datos sin generar grÃ¡fico
â€¢ `/creargrafica` - Crear grÃ¡fico basado en anÃ¡lisis previo
â€¢ `/datahistory` - Ver historial de anÃ¡lisis
â€¢ `/cleardata` - Limpiar historial de datos

**ðŸ“Š Tipos de GrÃ¡ficos Disponibles:**

**ðŸ”µ GrÃ¡ficos BÃ¡sicos:**
â€¢ **Barras** - Para comparar categorÃ­as
â€¢ **Circular/Pie** - Para mostrar proporciones
â€¢ **LÃ­nea** - Para mostrar tendencias
â€¢ **DispersiÃ³n** - Para mostrar correlaciones
â€¢ **Ãrea** - Para mostrar acumulaciÃ³n

**ðŸ”¥ GrÃ¡ficos Avanzados:**
â€¢ **Heatmap** - Mapa de calor para matrices
â€¢ **Treemap** - Mapa de Ã¡rbol jerÃ¡rquico
â€¢ **Sunburst** - GrÃ¡fico radial jerÃ¡rquico
â€¢ **Funnel** - Embudo de conversiÃ³n
â€¢ **Waterfall** - Cascada financiera
â€¢ **Sankey** - Diagrama de flujo

**ðŸ“ˆ GrÃ¡ficos EstadÃ­sticos:**
â€¢ **Box Plot** - DistribuciÃ³n y cuartiles
â€¢ **ViolÃ­n** - DistribuciÃ³n de densidad
â€¢ **Histograma** - DistribuciÃ³n de frecuencias
â€¢ **Density** - Mapa de densidad

**ðŸŒ Visualizaciones 3D:**
â€¢ **3D Scatter** - DispersiÃ³n tridimensional
â€¢ **Surface** - Superficie 3D
â€¢ **Contour** - Curvas de nivel
â€¢ **3D Surface** - Terreno 3D

**ðŸŽ¯ GrÃ¡ficos Especializados:**
â€¢ **Polar** - Coordenadas polares
â€¢ **Radar** - GrÃ¡fico de araÃ±a
â€¢ **Candlestick** - Velas financieras
â€¢ **Gauge** - Medidor circular
â€¢ **Indicator** - Indicador KPI
â€¢ **Timeline** - LÃ­nea de tiempo
â€¢ **Bubble** - GrÃ¡fico de burbujas

**ðŸ—ºï¸ GrÃ¡ficos GeogrÃ¡ficos:**
â€¢ **Map** - Mapa de dispersiÃ³n
â€¢ **Choropleth** - Mapa coroplÃ©tico

**ðŸ”¢ AnÃ¡lisis MatemÃ¡tico Disponible:**
â€¢ **Suma** - `suma de [columna]` o `total de [columna]`
â€¢ **Promedio** - `promedio de [columna]` o `media de [columna]`
â€¢ **Mediana** - `mediana de [columna]`
â€¢ **MÃ­nimo/MÃ¡ximo** - `mÃ­nimo de [columna]` o `mÃ¡ximo de [columna]`
â€¢ **EstadÃ­sticas** - `estadÃ­sticas de [columna]` (completo)
â€¢ **CorrelaciÃ³n** - `correlaciÃ³n entre [columna1] y [columna2]`
â€¢ **Conteo** - `conteo de [columna]`
â€¢ **DesviaciÃ³n estÃ¡ndar** - `desviaciÃ³n de [columna]`
â€¢ **Varianza** - `varianza de [columna]`

**ðŸ’¡ Ejemplos de Solicitudes Avanzadas:**
â€¢ "Hay 50 personas, 30 cumplen en diciembre y 15 en enero, crea un mapa de calor"
â€¢ "En mi empresa: 25 empleados en ventas, 15 en marketing, 10 en IT, haz un treemap"
â€¢ "Ventas por mes: enero 100, febrero 150, marzo 200, crea un diagrama de flujo"
â€¢ "DistribuciÃ³n de edades: 20-30 aÃ±os: 40 personas, 30-40 aÃ±os: 30 personas, haz un radar"
â€¢ "Datos financieros: crea velas japonesas"
â€¢ "Proceso de conversiÃ³n: crea un embudo"
â€¢ "Datos geogrÃ¡ficos: crea un mapa coroplÃ©tico"

**ðŸŽ¯ CaracterÃ­sticas Avanzadas:**
â€¢ AnÃ¡lisis automÃ¡tico de patrones con Gemini
â€¢ Almacenamiento inteligente de datos
â€¢ GrÃ¡ficos mejorados con insights de IA
â€¢ Recomendaciones personalizadas de visualizaciÃ³n
â€¢ Historial completo de anÃ¡lisis realizados
â€¢ DetecciÃ³n automÃ¡tica del tipo de grÃ¡fico mÃ¡s apropiado
â€¢ Soporte para mÃ¡s de 25 tipos de grÃ¡ficos diferentes

**ðŸ”„ Flujo de Trabajo Recomendado:**
1. **Analizar datos:** `/analyze Hay 50 personas, 33 son niÃ±os y el resto son niÃ±as`
2. **Crear grÃ¡fico:** `/creargrafica` (usa el anÃ¡lisis previo automÃ¡ticamente)
3. **Ver historial:** `/datahistory` (revisar anÃ¡lisis anteriores)

**Notas:**
â€¢ El bot detecta automÃ¡ticamente las columnas numÃ©ricas y categÃ³ricas
â€¢ Gemini analiza y estructura los datos para mejor visualizaciÃ³n
â€¢ Los grÃ¡ficos incluyen anÃ¡lisis de patrones integrado
â€¢ Todos los anÃ¡lisis se almacenan para referencia futura
â€¢ Puedes especificar el tipo de grÃ¡fico o dejar que el bot lo detecte automÃ¡ticamente
"""
    
    await update.message.reply_text(help_text)

async def data_history_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show user's data analysis history"""
    chat_id = update.effective_chat.id
    
    try:
        datasets = get_stored_datasets(chat_id)
        
        if not datasets:
            await update.message.reply_text("ðŸ“Š No tienes anÃ¡lisis de datos almacenados aÃºn.\n\nðŸ’¡ EnvÃ­a datos descriptivos para generar grÃ¡ficos y anÃ¡lisis.")
            return
        
        history_text = "ðŸ“Š **Historial de AnÃ¡lisis de Datos:**\n\n"
        
        for i, dataset in enumerate(datasets[-5:], 1):  # Show last 5
            timestamp = dataset['timestamp'][:16].replace('T', ' ')
            history_text += f"**{i}. {dataset['data_type']}** ({timestamp})\n"
            history_text += f"â€¢ CategorÃ­as: {', '.join(dataset['categories'][:3])}{'...' if len(dataset['categories']) > 3 else ''}\n"
            history_text += f"â€¢ AnÃ¡lisis: {dataset['analysis'][:100]}{'...' if len(dataset['analysis']) > 100 else ''}\n\n"
        
        if len(datasets) > 5:
            history_text += f"... y {len(datasets) - 5} anÃ¡lisis mÃ¡s"
        
        await update.message.reply_text(history_text)
        
    except Exception as e:
        await update.message.reply_text(f"âŒ Error obteniendo historial: {e}")

async def clear_data_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Clear user's stored data analysis history"""
    chat_id = update.effective_chat.id
    
    try:
        storage_file = f"user_data_{chat_id}.json"
        if os.path.exists(storage_file):
            os.remove(storage_file)
            await update.message.reply_text("ðŸ—‘ï¸ Historial de anÃ¡lisis de datos eliminado exitosamente.")
        else:
            await update.message.reply_text("ðŸ“Š No hay datos almacenados para eliminar.")
            
    except Exception as e:
        await update.message.reply_text(f"âŒ Error eliminando datos: {e}")

async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Analyze text data without generating chart"""
    chat_id = update.effective_chat.id
    user_message = update.message.text.replace('/analyze', '').strip()
    
    if not user_message:
        await update.message.reply_text("ðŸ“ Usa: /analyze [datos para analizar]\n\nEjemplo: /analyze Hay 50 personas, 30 cumplen en diciembre y 15 en enero")
        return
    
    try:
        await update.message.reply_text("ðŸ§  Analizando datos con IA avanzada...")
        
        # usar Gemini para analizar los datos
        gemini_url = os.getenv("GEMINI_API_URL")
        gemini_key = os.getenv("GEMINI_API_KEY")
        
        if gemini_url and gemini_key:
            analysis = analyze_data_with_gemini(user_message, chat_id, gemini_url, gemini_key)
            
            if analysis:
                # almacenar los datos analizados con tipo de grÃ¡fico para uso posterior
                store_analyzed_data(
                    chat_id, 
                    analysis['data_type'], 
                    analysis['categories'], 
                    analysis['values'], 
                    analysis['analysis'],
                    analysis['chart_type'],
                    analysis['title']
                )
                
                analysis_text = f"ðŸ” **AnÃ¡lisis Detallado:**\n\n"
                analysis_text += f"ðŸ“Š **Tipo de datos:** {analysis['data_type']}\n"
                analysis_text += f"ðŸ·ï¸ **CategorÃ­as identificadas:** {', '.join(analysis['categories'])}\n"
                analysis_text += f"ðŸ“ˆ **Valores extraÃ­dos:**\n"
                
                for category, value in analysis['values'].items():
                    analysis_text += f"â€¢ {category}: {value}\n"
                
                analysis_text += f"\nðŸŽ¯ **GrÃ¡fico recomendado:** {analysis['chart_type'].title()}\n"
                analysis_text += f"ðŸ“ **TÃ­tulo sugerido:** {analysis['title']}\n\n"
                analysis_text += f"ðŸ§  **AnÃ¡lisis de patrones:**\n{analysis['analysis']}\n\n"
                analysis_text += f"ðŸ’¡ **Para crear el grÃ¡fico, usa:** `/creargrafica`"
                
                await update.message.reply_text(analysis_text)
            else:
                await update.message.reply_text("âŒ No se pudo analizar los datos. Intenta con un formato mÃ¡s claro.")
        else:
            await update.message.reply_text("âŒ Gemini no estÃ¡ configurado para anÃ¡lisis avanzado.")
            
    except Exception as e:
        await update.message.reply_text(f"âŒ Error en anÃ¡lisis: {e}")

async def create_chart_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Create chart based on previous analysis"""
    chat_id = update.effective_chat.id
    
    try:
        # obtener los Ãºltimos datos analizados para este usuario
        last_analysis = get_last_analyzed_data(chat_id)
        
        if not last_analysis:
            await update.message.reply_text(
                "âŒ No hay datos analizados previos.\n\n"
                "ðŸ“ **Pasos para crear un grÃ¡fico:**\n"
                "1. Usa `/analyze [tus datos]` para analizar los datos\n"
                "2. Luego usa `/creargrafica` para generar el grÃ¡fico\n\n"
                "**Ejemplo:**\n"
                "`/analyze Hay 50 personas, 33 son niÃ±os y el resto son niÃ±as`\n"
                "`/creargrafica`"
            )
            return
        
        await update.message.reply_text("ðŸŽ¨ Generando grÃ¡fico basado en el anÃ¡lisis previo...")
        
        # Create chart using the stored analysis
        chart_bytes, message = create_chart_from_text_data(
            last_analysis['values'], 
            last_analysis['chart_type'], 
            last_analysis['title']
        )
        
        if chart_bytes:
            # enviar el grÃ¡fico como foto
            await update.message.reply_photo(
                photo=io.BytesIO(chart_bytes),
                caption=f"ðŸ“Š **{last_analysis['title']}**\n\n"
                       f"ðŸ“ˆ **Tipo:** {last_analysis['chart_type'].title()}\n"
                       f"ðŸ“Š **Datos:** {last_analysis['data_type']}\n\n"
                       f"ðŸ’¡ **AnÃ¡lisis:**\n{last_analysis['analysis']}"
            )
            
            # agregar creaciÃ³n de grÃ¡fico a memoria
            add_to_memory(chat_id, "assistant", f"GrÃ¡fico creado: {last_analysis['title']} ({last_analysis['chart_type']})")
            
        else:
            await update.message.reply_text(message if message else "âŒ Error generando el grÃ¡fico. Intenta analizar los datos nuevamente.")
            
    except Exception as e:
        await update.message.reply_text(f"âŒ Error creando grÃ¡fico: {e}")
        print(f"Error in create_chart_command: {e}")

# comando /echo
async def echo_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # join args provided after /echo
    text = " ".join(context.args) if context.args else ""
    if not text:
        await update.message.reply_text("Uso: /echo <texto>")
        return

    chat_id = update.effective_chat.id
    add_to_memory(chat_id, "user", text)

    gemini_url = os.getenv("GEMINI_API_URL")
    gemini_key = os.getenv("GEMINI_API_KEY")
    if gemini_url and gemini_key:
        try:
            response_text = await query_gemini_with_memory(text, chat_id, gemini_url, gemini_key)
        except Exception as e:
            response_text = f"Error al llamar a Gemini: {e}"
    else:
        response_text = text

    add_to_memory(chat_id, "assistant", response_text)
    await update.message.reply_text(response_text)

# comando /clear
async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    clear_memory(chat_id)
    await update.message.reply_text("âœ… Historial de conversaciÃ³n limpiado.")

# comando /audio_limit
async def audio_limit_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Show current audio character limit"""
    MAX_AUDIO_CHARS = int(os.getenv("MAX_AUDIO_CHARS", "1000"))
    
    current_limit = MAX_AUDIO_CHARS
    limit_info = f"""
ðŸŽµ **ConfiguraciÃ³n de LÃ­mite de Audio**

ðŸ“Š **LÃ­mite actual:** {current_limit} caracteres

â±ï¸ **DuraciÃ³n aproximada:** ~{current_limit // 10} segundos

ðŸ”§ **Para cambiar el lÃ­mite:**
1. Edita el archivo `.env`
2. Cambia `MAX_AUDIO_CHARS=tu_valor`
3. Reinicia el bot

ðŸ“‹ **Valores recomendados:**
â€¢ 500 - Respuestas cortas (~30s)
â€¢ 1000 - Respuestas medianas (~1min) â­
â€¢ 2000 - Respuestas largas (~2min)
â€¢ 3000 - Respuestas muy largas (~3min)
â€¢ 5000 - MÃ¡ximo tÃ©cnico (~5min)

âš ï¸ **Nota:** Valores muy altos pueden causar problemas de calidad.
"""
    
    await update.message.reply_text(limit_info)

async def set_audio_limit_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Set audio character limit"""
    if not context.args:
        await update.message.reply_text("âŒ Uso: /setaudiolimit <nÃºmero>\nEjemplo: /setaudiolimit 2000")
        return
    
    try:
        new_limit = int(context.args[0])
        
        if new_limit < 100:
            await update.message.reply_text("âŒ El lÃ­mite mÃ­nimo es 100 caracteres")
            return
        
        if new_limit > 5000:
            await update.message.reply_text("âŒ El lÃ­mite mÃ¡ximo es 5000 caracteres")
            return
        
        # actualizar archivo .env
        try:
            with open('.env', 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            updated = False
            for i, line in enumerate(lines):
                if line.startswith('MAX_AUDIO_CHARS='):
                    lines[i] = f'MAX_AUDIO_CHARS={new_limit}\n'
                    updated = True
                    break
            
            if not updated:
                lines.append(f'MAX_AUDIO_CHARS={new_limit}\n')
            
            with open('.env', 'w', encoding='utf-8') as f:
                f.writelines(lines)
            
            await update.message.reply_text(f"âœ… LÃ­mite de audio cambiado a {new_limit} caracteres\n\nðŸ”„ Reinicia el bot para aplicar el cambio.")
            
        except Exception as e:
            await update.message.reply_text(f"âŒ Error actualizando configuraciÃ³n: {e}")
            
    except ValueError:
        await update.message.reply_text("âŒ Por favor ingresa un nÃºmero vÃ¡lido")

async def memory_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    memory = get_chat_memory(chat_id)
    
    if not memory:
        await update.message.reply_text("No hay historial de conversaciÃ³n.")
        return
    
    memory_text = "ðŸ“ Historial de conversaciÃ³n:\n\n"
    for i, msg in enumerate(memory[-10:], 1):  # mostrar Ãºltimos 10 mensajes
        role_emoji = "ðŸ‘¤" if msg["role"] == "user" else "ðŸ¤–"
        memory_text += f"{i}. {role_emoji} {msg['role']}: {msg['content'][:100]}{'...' if len(msg['content']) > 100 else ''}\n"
    
    await update.message.reply_text(memory_text)


# respuesta a cualquier mensaje de texto
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    chat_id = update.effective_chat.id
    
    # agregar mensaje del usuario a memoria
    add_to_memory(chat_id, "user", user_message)

    # verificar si el usuario estÃ¡ solicitando anÃ¡lisis desde Excel cargado
    if EXCEL_CHARTS_AVAILABLE and 'excel_sheets' in context.user_data:
        chart_keywords = ['grÃ¡fico', 'grafico', 'grÃ¡fica', 'grafica', 'chart', 'diagrama', 'barras', 'barra', 'circular', 'pie', 'torta', 'pastel', 'lÃ­nea', 'linea', 'line', 'tendencia', 'dispersiÃ³n', 'dispersion', 'scatter', 'puntos', 'histograma', 'histogram']
        
        # verificar solicitudes de grÃ¡ficos
        if any(keyword in user_message.lower() for keyword in chart_keywords):
            try:
                await update.message.reply_text("ðŸ“Š Generando grÃ¡fico desde Excel...")
                
                # detectar tipo de grÃ¡fico
                chart_type = detect_chart_type_from_text(user_message)
                
                # obtener informaciÃ³n de hojas desde contexto
                sheets_info = context.user_data['excel_sheets']
                file_name = context.user_data.get('excel_file_name', 'archivo')
                
                # usar primera hoja
                selected_sheet = list(sheets_info.keys())[0]
                df = sheets_info[selected_sheet]['dataframe']
                
                # generar tÃ­tulo
                title = f"GrÃ¡fico de {selected_sheet} - {chart_type.title()}"
                
                # crear grÃ¡fico (preferir plotly para mejor calidad)
                chart_bytes = create_plotly_chart(df, chart_type, title)
                if not chart_bytes:
                    chart_bytes = create_matplotlib_chart(df, chart_type, title)
                
                if chart_bytes:
                    await update.message.reply_photo(
                        photo=io.BytesIO(chart_bytes),
                        caption=f"ðŸ“Š GrÃ¡fico generado desde {file_name} - Hoja: {selected_sheet}"
                    )
                    add_to_memory(chat_id, "assistant", f"GrÃ¡fico {chart_type} generado desde Excel")
                    return
                else:
                    await update.message.reply_text("âŒ Error generando el grÃ¡fico")
                    return
                    
            except Exception as e:
                await update.message.reply_text(f"âŒ Error generando grÃ¡fico: {e}")
                return
        
        # verificar solicitudes de anÃ¡lisis matemÃ¡tico
        elif detect_mathematical_request(user_message):
            try:
                await update.message.reply_text("ðŸ”¢ Realizando anÃ¡lisis matemÃ¡tico...")
                
                # obtener informaciÃ³n de hojas desde contexto
                sheets_info = context.user_data['excel_sheets']
                file_name = context.user_data.get('excel_file_name', 'archivo')
                
                # usar primera hoja
                selected_sheet = list(sheets_info.keys())[0]
                df = sheets_info[selected_sheet]['dataframe']
                
                # extraer tipo de anÃ¡lisis y nombres de columnas
                available_columns = list(df.columns)
                found_columns = extract_column_names(user_message, available_columns)
                
                # determinar tipo de anÃ¡lisis
                analysis_type = "estadÃ­sticas"  # Default
                if any(word in user_message.lower() for word in ['suma', 'sum', 'total']):
                    analysis_type = "suma"
                elif any(word in user_message.lower() for word in ['promedio', 'average', 'mean']):
                    analysis_type = "promedio"
                elif any(word in user_message.lower() for word in ['mediana', 'median']):
                    analysis_type = "mediana"
                elif any(word in user_message.lower() for word in ['minimo', 'min', 'mÃ­nimo']):
                    analysis_type = "minimo"
                elif any(word in user_message.lower() for word in ['maximo', 'max', 'mÃ¡ximo']):
                    analysis_type = "maximo"
                elif any(word in user_message.lower() for word in ['estadisticas', 'stats', 'estadÃ­sticas']):
                    analysis_type = "estadisticas"
                elif any(word in user_message.lower() for word in ['correlacion', 'correlation']):
                    analysis_type = "correlacion"
                elif any(word in user_message.lower() for word in ['conteo', 'count']):
                    analysis_type = "conteo"
                elif any(word in user_message.lower() for word in ['desviacion', 'std']):
                    analysis_type = "desviacion"
                elif any(word in user_message.lower() for word in ['varianza', 'variance']):
                    analysis_type = "varianza"
                
                # realizar anÃ¡lisis
                column_name = found_columns[0] if found_columns else None
                column2_name = found_columns[1] if len(found_columns) > 1 else None
                
                result, error = perform_mathematical_analysis(df, analysis_type, column_name, column2_name)
                
                if result:
                    await update.message.reply_text(f"ðŸ“Š **AnÃ¡lisis matemÃ¡tico de {file_name}**\n\n{result}")
                    add_to_memory(chat_id, "assistant", f"AnÃ¡lisis matemÃ¡tico {analysis_type} realizado")
                    return
                else:
                    await update.message.reply_text(f"âŒ {error}")
                    return
                    
            except Exception as e:
                await update.message.reply_text(f"âŒ Error en anÃ¡lisis matemÃ¡tico: {e}")
                return
    
    # verificar si el usuario estÃ¡ solicitando un grÃ¡fico desde texto descriptivo (no Excel)
    elif EXCEL_CHARTS_AVAILABLE and detect_chart_request_from_text(user_message):
        try:
            await update.message.reply_text("ðŸ§  Analizando datos con IA avanzada...")
            
            # extraer datos desde texto
            extracted_data, total_count = extract_data_from_text(user_message)
            
            if not extracted_data:
                await update.message.reply_text("âŒ No pude extraer datos numÃ©ricos del texto. AsegÃºrate de incluir nÃºmeros y categorÃ­as.")
                return
            
            # usar Gemini para analizar los datos
            gemini_url = os.getenv("GEMINI_API_URL")
            gemini_key = os.getenv("GEMINI_API_KEY")
            
            if gemini_url and gemini_key:
                await update.message.reply_text("ðŸ” Gemini estÃ¡ analizando los patrones de datos...")
                
                # analizar con Gemini
                analysis = analyze_data_with_gemini(user_message, chat_id, gemini_url, gemini_key)
                
                if analysis and analysis['values']:
                    # usar anÃ¡lisis de Gemini para mejor generaciÃ³n de grÃ¡fico
                    extracted_data = analysis['values']
                    chart_type = analysis['chart_type']
                    title = analysis['title']
                    
                    # almacenar los datos analizados
                    store_analyzed_data(
                        chat_id, 
                        analysis['data_type'], 
                        analysis['categories'], 
                        analysis['values'], 
                        analysis['analysis']
                    )
                    
                    await update.message.reply_text(f"âœ… **AnÃ¡lisis completado:**\n\nðŸ“Š **Tipo de datos:** {analysis['data_type']}\nðŸŽ¯ **GrÃ¡fico recomendado:** {chart_type.title()}\nðŸ“ˆ **TÃ­tulo:** {title}\n\nðŸ” **AnÃ¡lisis de patrones:**\n{analysis['analysis']}")
                else:
                        # por defecto: grÃ¡fico de torta
                    chart_type = "pie"
                    title = f"DistribuciÃ³n de {total_count} elementos" if total_count else "GrÃ¡fico de Datos"
                    analysis = {'analysis': 'AnÃ¡lisis bÃ¡sico realizado'}
            else:
                # por defecto: grÃ¡fico de torta
                chart_type = "pie"
                title = f"DistribuciÃ³n de {total_count} elementos" if total_count else "GrÃ¡fico de Datos"
                analysis = {'analysis': 'AnÃ¡lisis bÃ¡sico realizado'}
            
            # verificar si el usuario desea anÃ¡lisis avanzado o diagramas de flujo
            analysis_type = detect_analysis_type_from_text(user_message)
            
            if analysis_type in ['flow_diagram', 'sankey']:
                await update.message.reply_text("ðŸ”„ Generando diagrama de flujo...")
                chart_bytes, message = create_flow_diagram(extracted_data, title)
            elif analysis_type in ['correlation_matrix', 'distribution_analysis', 'outlier_detection', 'trend_analysis', 'comparative_analysis']:
                await update.message.reply_text(f"ðŸ“ˆ Generando anÃ¡lisis {analysis_type}...")
                chart_bytes, message = create_advanced_analysis(extracted_data, analysis_type, title)
            else:
                # crear grÃ¡fico mejorado
                await update.message.reply_text("ðŸ“Š Generando grÃ¡fico mejorado...")
                chart_bytes, message = create_chart_from_text_data(extracted_data, chart_type, title)
            
            if chart_bytes:
                # mejorar grÃ¡fico con anÃ¡lisis
                enhanced_chart_bytes = enhance_chart_with_analysis(chart_bytes, analysis, extracted_data)
                
                # mostrar resumen de datos procesados
                data_summary = "ðŸ“Š **Datos procesados:**\n"
                for category, value in extracted_data.items():
                    percentage = (value / sum(extracted_data.values())) * 100
                    data_summary += f"â€¢ {category}: {value} ({percentage:.1f}%)\n"
                
                await update.message.reply_text(data_summary)
                
                # enviar grÃ¡fico mejorado
                chart_caption = f"ðŸ“Š {analysis_type.replace('_', ' ').title()} generado con anÃ¡lisis de IA" if analysis_type != 'pie' else "ðŸ“Š GrÃ¡fico inteligente generado con anÃ¡lisis de IA"
                await update.message.reply_photo(
                    photo=io.BytesIO(enhanced_chart_bytes),
                    caption=chart_caption
                )
                add_to_memory(chat_id, "assistant", f"AnÃ¡lisis {analysis_type} generado con anÃ¡lisis avanzado de Gemini")
                return
            else:
                await update.message.reply_text(f"âŒ {message}")
                return
                
        except Exception as e:
            await update.message.reply_text(f"âŒ Error en anÃ¡lisis avanzado: {e}")
            return

    # si Gemini estÃ¡ configurado, enviar mensaje del usuario a Gemini
    gemini_url = os.getenv("GEMINI_API_URL")
    gemini_key = os.getenv("GEMINI_API_KEY")

    if gemini_url and gemini_key:
        try:
            response_text = await query_gemini_with_memory(user_message, chat_id, gemini_url, gemini_key)
        except Exception as e:
            response_text = f"Error al llamar a Gemini: {e}"
    else:
        response_text = f"RecibÃ­ tu mensaje: {user_message}"

    # agregar respuesta del asistente a memoria
    add_to_memory(chat_id, "assistant", response_text)
    await update.message.reply_text(response_text)


# manejador para mensajes de voz
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle voice messages: transcribe, process with Gemini, and respond with audio"""
    if not VOICE_AVAILABLE:
        await update.message.reply_text("âŒ Funcionalidad de voz no disponible. Error con las dependencias de audio.")
        return
        
    chat_id = update.effective_chat.id
    voice = update.message.voice
    
    # enviar mensaje de procesamiento
    processing_msg = await update.message.reply_text("ðŸŽ¤ Procesando mensaje de voz...")
    
    try:
        # crear directorio temporal para procesamiento de audio
        with tempfile.TemporaryDirectory() as temp_dir:
            ogg_path = os.path.join(temp_dir, "voice.ogg")
            wav_path = os.path.join(temp_dir, "voice.wav")
            
            # descargar archivo de voz
            success = await download_voice_file(voice.file_id, ogg_path, TOKEN)
            if not success:
                await processing_msg.edit_text("âŒ Error descargando el archivo de voz")
                return
            
            # convertir formato de audio OGG a WAV
            await processing_msg.edit_text("ðŸŽ¤ Convirtiendo formato de audio...")
            success = convert_audio_format(ogg_path, wav_path)
            if not success:
                await processing_msg.edit_text("âŒ Error convirtiendo el audio. Intentando transcripciÃ³n directa...")
                # intentar transcribir archivo de voz original OGG directamente
                wav_path = ogg_path
            
            # transcribir audio
            await processing_msg.edit_text("ðŸŽ¤ Transcribiendo audio...")
            transcription, detected_language = transcribe_audio(wav_path)
            
            if not transcription or transcription == "No pude transcribir el audio. Por favor, intenta enviar un mensaje de texto.":
                await processing_msg.edit_text("âŒ Error transcribiendo el audio. Usando transcripciÃ³n alternativa...")
                # intentar transcribir audio con Google Speech Recognition directamente
                try:
                    import speech_recognition as sr
                    r = sr.Recognizer()
                    with sr.AudioFile(wav_path) as source:
                        audio = r.record(source)
                    transcription = r.recognize_google(audio, language='es-ES')
                    detected_language = 'es-ES'
                except Exception as e:
                    await processing_msg.edit_text("âŒ No pude transcribir el audio. Por favor, intenta enviar un mensaje de texto.")
                    return
            
            # agregar transcripciÃ³n a memoria
            add_to_memory(chat_id, "user", f"[VOZ] {transcription}")
            
            # obtener respuesta de Gemini
            await processing_msg.edit_text("ðŸ¤– Generando respuesta...")
            gemini_url = os.getenv("GEMINI_API_URL")
            gemini_key = os.getenv("GEMINI_API_KEY")
            
            if gemini_url and gemini_key:
                try:
                    response_text = await query_gemini_with_memory(transcription, chat_id, gemini_url, gemini_key)
                except Exception as e:
                    response_text = f"Error al llamar a Gemini: {e}"
            else:
                response_text = f"TranscripciÃ³n: {transcription}"
            
            # agregar respuesta a memoria
            add_to_memory(chat_id, "assistant", response_text)
            
            # enviar respuesta de texto
            await processing_msg.edit_text(f"ðŸ“ **TranscripciÃ³n:** {transcription}\n\nðŸ¤– **Respuesta:** {response_text}")
            
                # generar y enviar respuesta de audio si estÃ¡ habilitado
            MAX_AUDIO_CHARS = int(os.getenv("MAX_AUDIO_CHARS", "5000"))  # lÃ­mite configurable
            if AUDIO_RESPONSE_ENABLED and len(response_text) < MAX_AUDIO_CHARS:
                try:
                    await processing_msg.edit_text(f"ðŸ“ **TranscripciÃ³n:** {transcription}\n\nðŸ¤– **Respuesta:** {response_text}\n\nðŸŽµ Generando respuesta en audio...")
                    
                    audio_file = generate_audio_response(response_text, detected_language)
                    if audio_file:
                        with open(audio_file, 'rb') as audio:
                            await update.message.reply_voice(
                                voice=audio,
                                caption="ðŸŽµ Respuesta en audio"
                            )
                            # limpiar archivo de audio temporal
                        os.unlink(audio_file)
                    else:
                        await update.message.reply_text("âš ï¸ No se pudo generar respuesta en audio")
                except Exception as e:
                    print(f"Error generating audio response: {e}")
                    await update.message.reply_text("âš ï¸ Error generando respuesta en audio")
            else:
                if not AUDIO_RESPONSE_ENABLED:
                    await update.message.reply_text("â„¹ï¸ Respuesta en audio deshabilitada")
                else:
                    await update.message.reply_text("â„¹ï¸ Respuesta muy larga para audio")
                    
    except Exception as e:
        print(f"Error processing voice message: {e}")
        await processing_msg.edit_text(f"âŒ Error procesando mensaje de voz: {str(e)}")

async def handle_document(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """Handle Excel document uploads and generate charts with robust file handling"""
    if not EXCEL_CHARTS_AVAILABLE:
        await update.message.reply_text("âŒ Funcionalidad de Excel y grÃ¡ficos no disponible. Error con las dependencias.")
        return
    
    chat_id = update.effective_chat.id
    document = update.message.document
    
    # verificar si es un archivo Excel
    if not document.file_name.lower().endswith(('.xlsx', '.xls')):
        await update.message.reply_text("âŒ Por favor envÃ­a un archivo Excel (.xlsx o .xls)")
        return
    
    # enviar mensaje de procesamiento
    processing_msg = await update.message.reply_text("ðŸ“Š Descargando archivo Excel...")
    
    try:
        # Descargar archivo directamente en memoria (evita problemas de bloqueo de archivos en Windows)
        file = await context.bot.get_file(document.file_id)
        
        # Descargar como bytes
        file_bytes = await file.download_as_bytearray()
        
        # Crear objeto BytesIO para leer en memoria
        file_buffer = io.BytesIO(file_bytes)
        
        # leer archivo Excel directamente desde memoria
        await processing_msg.edit_text("ðŸ“Š Leyendo archivo Excel...")
        
        sheets_info = read_excel_file(file_buffer)
        
        if not sheets_info:
            await processing_msg.edit_text(
                "âŒ Error leyendo el archivo Excel.\n\n"
                "ðŸ’¡ **Posibles causas:**\n"
                "â€¢ El archivo estÃ¡ corrupto\n"
                "â€¢ El archivo estÃ¡ protegido con contraseÃ±a\n"
                "â€¢ El formato no es compatible\n\n"
                "ðŸ”§ **Soluciones:**\n"
                "â€¢ Guarda el archivo como nuevo Excel (.xlsx)\n"
                "â€¢ Elimina la protecciÃ³n de contraseÃ±a si tiene\n"
                "â€¢ Intenta con un archivo mÃ¡s simple"
            )
            return
        
        # Realizar anÃ¡lisis completo de cada hoja
        await processing_msg.edit_text("ðŸ“Š Analizando datos...")
        
        detailed_analysis = {}
        sheets_summary = []
        
        for name, info in sheets_info.items():
            df = info['dataframe']
            
            # AnÃ¡lisis completo de esta hoja
            analysis = get_comprehensive_data_analysis(df)
            detailed_analysis[name] = analysis
            
            # Resumen para mostrar al usuario
            numeric_cols = len(analysis['numeric_columns'])
            text_cols = len(analysis['text_columns'])
            date_cols = len(analysis['date_columns'])
            
            # Mostrar columnas numÃ©ricas encontradas
            num_cols_text = ", ".join(analysis['numeric_columns'][:3])
            if len(analysis['numeric_columns']) > 3:
                num_cols_text += f" (y {len(analysis['numeric_columns']) - 3} mÃ¡s)"
            
            sheet_info = f"ðŸ“„ **{name}**\n"
            sheet_info += f"   â€¢ {info['shape'][0]} filas Ã— {info['shape'][1]} columnas\n"
            sheet_info += f"   â€¢ {numeric_cols} numÃ©ricas"
            if num_cols_text:
                sheet_info += f": {num_cols_text}"
            sheet_info += f"\n   â€¢ {text_cols} de texto, {date_cols} de fecha"
            
            sheets_summary.append(sheet_info)
        
        sheets_text = "\n\n".join(sheets_summary)
        
        # Mensaje detallado para el usuario
        response_msg = (
            f"âœ… **Archivo Excel procesado exitosamente!**\n\n"
            f"ðŸ“‹ **AnÃ¡lisis de hojas:**\n\n{sheets_text}\n\n"
            f"ðŸ’¡ **Â¿QuÃ© puedo hacer ahora?**\n\n"
            f"ðŸ“Š **GrÃ¡ficos:**\n"
            f"   â€¢ \"crea un grÃ¡fico de barras\"\n"
            f"   â€¢ \"grÃ¡fico de lÃ­neas con [columna]\"\n"
            f"   â€¢ \"grÃ¡fico de dispersiÃ³n entre X y Y\"\n"
            f"   â€¢ \"histograma de [columna]\"\n\n"
            f"ðŸ”¢ **AnÃ¡lisis matemÃ¡tico:**\n"
            f"   â€¢ \"calcula la suma de [columna]\"\n"
            f"   â€¢ \"promedio y mediana de [columna]\"\n"
            f"   â€¢ \"estadÃ­sticas completas de [columna]\"\n"
            f"   â€¢ \"correlaciÃ³n entre [columna1] y [columna2]\"\n\n"
            f"ðŸ“ˆ **AnÃ¡lisis avanzado:**\n"
            f"   â€¢ \"muestra las 10 filas con mayor [columna]\"\n"
            f"   â€¢ \"agrupa por [columna] y suma [otra columna]\"\n"
            f"   â€¢ \"encuentra valores atÃ­picos en [columna]\""
        )
        
        await processing_msg.edit_text(response_msg)
        
        # almacenar informaciÃ³n del archivo en contexto para uso posterior
        context.user_data['excel_sheets'] = sheets_info
        context.user_data['excel_analysis'] = detailed_analysis
        context.user_data['excel_file_name'] = document.file_name
        
        # Crear contexto detallado para Gemini
        data_context = f"ARCHIVO EXCEL CARGADO: {document.file_name}\n\n"
        for sheet_name, analysis in detailed_analysis.items():
            data_context += f"HOJA: {sheet_name}\n"
            data_context += f"- Total de filas: {analysis['total_rows']}\n"
            data_context += f"- Columnas totales: {analysis['total_columns']}\n"
            
            if analysis['numeric_columns']:
                data_context += f"- Columnas numÃ©ricas: {', '.join(analysis['numeric_columns'])}\n"
                for col in analysis['numeric_columns']:
                    stats = analysis['statistics'].get(col, {})
                    data_context += f"  * {col}: promedio={stats.get('mean', 0):.2f}, min={stats.get('min', 0):.2f}, max={stats.get('max', 0):.2f}, suma={stats.get('sum', 0):.2f}\n"
            
            if analysis['text_columns']:
                data_context += f"- Columnas de texto: {', '.join(analysis['text_columns'])}\n"
            
            if analysis['date_columns']:
                data_context += f"- Columnas de fecha: {', '.join(analysis['date_columns'])}\n"
            
            data_context += "\n"
        
        # agregar a memoria la informaciÃ³n del archivo con contexto completo
        add_to_memory(chat_id, "user", f"[EXCEL] SubÃ­ archivo: {document.file_name}")
        add_to_memory(chat_id, "assistant", data_context)
        
    except Exception as e:
        error_msg = str(e)
        print(f"Error processing Excel file: {error_msg}")
        
        # Mensaje de error mÃ¡s especÃ­fico
        if "password" in error_msg.lower() or "encrypted" in error_msg.lower():
            await processing_msg.edit_text(
                "âŒ **Error: Archivo protegido**\n\n"
                "El archivo estÃ¡ protegido con contraseÃ±a.\n\n"
                "ðŸ”§ **SoluciÃ³n:**\n"
                "1. Abre el archivo en Excel\n"
                "2. Ve a Archivo > InformaciÃ³n > Proteger libro\n"
                "3. Elimina la contraseÃ±a\n"
                "4. Guarda el archivo\n"
                "5. Intenta subirlo de nuevo"
            )
        else:
            await processing_msg.edit_text(
                f"âŒ **Error procesando archivo Excel**\n\n"
                f"**Detalles:** `{error_msg[:150]}`\n\n"
                "ðŸ’¡ **Sugerencias:**\n"
                "â€¢ Verifica que el archivo no estÃ© corrupto\n"
                "â€¢ AsegÃºrate de que no estÃ© protegido con contraseÃ±a\n"
                "â€¢ Intenta con un archivo mÃ¡s pequeÃ±o (< 10MB)\n"
                "â€¢ Guarda el archivo como nuevo Excel (.xlsx)\n"
                "â€¢ AsegÃºrate de que sea un archivo Excel vÃ¡lido\n\n"
                "ðŸ”„ Intenta de nuevo o contacta soporte si el problema persiste."
            )

async def query_gemini_with_memory(prompt: str, chat_id: int, api_url: str, api_key: str, timeout: Optional[float] = 15.0) -> str:
    """Send prompt with conversation history to Gemini API and return the text response."""
    # obtener historial de conversaciÃ³n
    memory = get_chat_memory(chat_id)
    
    # agregar informaciÃ³n de fecha y hora actual
    import pytz
    import locale
    
    # establecer locale para nombres de dÃ­a y mes en espaÃ±ol
    try:
        locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')
    except:
        try:
            locale.setlocale(locale.LC_TIME, 'Spanish_Spain.1252')
        except:
            pass  # usar valor por defecto si locale en espaÃ±ol no estÃ¡ disponible
    
    # obtener hora actual en zona horaria (ajustar zona horaria segÃºn sea necesario)
    tz = pytz.timezone('America/Mexico_City')  # Change to your timezone
    current_time = datetime.now(tz)
    
    # formatear fecha y hora
    day_name = current_time.strftime('%A')
    date_str = current_time.strftime('%d de %B de %Y')
    time_str = current_time.strftime('%H:%M:%S')
    
    # construir contexto de conversaciÃ³n con fecha y hora actual
    conversation_parts = []
    
    # agregar contexto del sistema con fecha y hora actual
    time_context = f"INFORMACIÃ“N DEL SISTEMA: Hoy es {day_name}, {date_str}. La hora actual es {time_str} ({tz.zone}). Usa esta informaciÃ³n para responder preguntas sobre la fecha y hora actuales."
    conversation_parts.append({"text": f"system: {time_context}"})
    
    # agregar contexto del perfil activo si existe
    # Primero intentar leer desde archivo de sincronizaciÃ³n (tiempo real)
    profile_context = ""
    if os.path.exists("active_profile_context.txt"):
        try:
            with open("active_profile_context.txt", 'r', encoding='utf-8') as f:
                profile_context = f.read().strip()
        except Exception as e:
            print(f"Error leyendo contexto sincronizado: {e}")
    
    # Si no existe archivo, usar PROFILE_MANAGER
    if not profile_context and PROFILE_MANAGER:
        profile_context = PROFILE_MANAGER.get_active_profile_context()
    
    # Agregar contexto si existe
    if profile_context:
        conversation_parts.append({"text": f"profile_context: {profile_context}"})
    
    for msg in memory:
        if msg["role"] in ["user", "assistant"]:
            conversation_parts.append({"text": f"{msg['role']}: {msg['content']}"})
    
    # agregar prompt actual
    conversation_parts.append({"text": f"user: {prompt}"})
    
    # unir contexto de conversaciÃ³n
    full_context = "\n".join([part["text"] for part in conversation_parts])
    
    return await query_gemini(full_context, api_url, api_key, timeout)

async def query_gemini(prompt: str, api_url: str, api_key: str, timeout: Optional[float] = 15.0) -> str:
    """Send prompt to Gemini API and return the text response.

    This expects the Gemini endpoint to accept a JSON payload like {"input": "..."}
    and return a JSON with a `text` field. Adjust the payload parsing if your API
    differs.
    """
    # preparar headers y url dependiendo de si la API key debe pasarse como parÃ¡metro de consulta (comÃºn para API keys) o como token Bearer.
    # passed as a query parameter (common for API keys) o como token Bearer.
    headers = {"Content-Type": "application/json"}
    url = api_url

    # si un archivo JSON de cuenta de servicio estÃ¡ disponible en el entorno, preferir token OAuth Bearer
    sa_path = os.getenv("GEMINI_SA_PATH") or os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if sa_path and os.path.exists(sa_path):
        # obtener un token de acceso con scope cloud-platform
        creds = service_account.Credentials.from_service_account_file(sa_path, scopes=["https://www.googleapis.com/auth/cloud-platform"])
        creds.refresh(GoogleRequest())
        token = creds.token
        headers["Authorization"] = f"Bearer {token}"
        # no agregar API key cuando se usa OAuth
        url = api_url
    else:
        # si la api_url no incluye ya un parÃ¡metro de API key, adjuntarlo para
        # servicios que esperan ?key=API_KEY (por ejemplo, algunos puntos finales de Google cuando se usan API keys).
        if api_key:
            if "key=" not in api_url:
                sep = "&" if "?" in api_url else "?"
                url = f"{api_url}{sep}key={api_key}"
            else:
                url = api_url
        else:
            url = api_url

        # si la url no contiene un parÃ¡metro de API key y la api_key parece
        # un token (cadena larga), aÃºn intentamos establecerlo como Bearer en el encabezado de Authorization
        # encabezado en caso de que el servicio espere OAuth Bearer.
        if api_key and "key=" not in url:
            headers["Authorization"] = f"Bearer {api_key}"

    # si la api_url no incluye ya un parÃ¡metro de API key, adjuntarlo para
    # servicios que esperan ?key=API_KEY (por ejemplo, algunos puntos finales de Google cuando se usan API keys).
    if api_key:
        if "key=" not in api_url:
            sep = "&" if "?" in api_url else "?"
            url = f"{api_url}{sep}key={api_key}"
        else:
            url = api_url
    else:
        # no se proporcionÃ³ api_key: nada que agregar
        url = api_url

    # si la url no contiene un parÃ¡metro de API key y la api_key parece
    # un token (cadena larga), aÃºn intentamos establecerlo como Bearer en el encabezado de Authorization
    # encabezado en caso de que el servicio espere OAuth Bearer.
    if api_key and "key=" not in url:
        headers["Authorization"] = f"Bearer {api_key}"

    # elegir payloads dependiendo de la familia del punto final.
    is_generate_content = (":generateContent" in url) or ("generativelanguage.googleapis.com" in url)
    is_vertex_predict = (":predict" in url) or ("aiplatform.googleapis.com" in url)

    if is_generate_content:
        # Gemini APIs de lenguaje generativo esperan `contents`
        payload_candidates = [
            {"contents": [{"role": "user", "parts": [{"text": prompt}]}]},
        ]
    elif is_vertex_predict:
        # Vertex AI Predict-style espera `instances` con un array `content`
        payload_candidates = [
            {"instances": [{"content": [{"role": "user", "parts": [{"text": prompt}]}]}]},
        ]
    else:
        # intentar un conjunto mÃ¡s amplio (excluyendo las variantes problemÃ¡ticas `input`)
        payload_candidates = [
            {"contents": [{"role": "user", "parts": [{"text": prompt}]}]},
            {"prompt": {"text": prompt}},
            {"instances": [{"content": prompt}]},
            {"instances": [{"content": [{"type": "text", "text": prompt}]}]},
        ]

    async with httpx.AsyncClient(timeout=timeout) as client:
        last_exc = None
        for payload in payload_candidates:
            try:
                r = await client.post(url, json=payload, headers=headers)
                # si es exitoso (2xx), parsear y devolver
                if 200 <= r.status_code < 300:
                    try:
                        data = r.json()
                    except Exception:
                        return r.text

                    # parsear varias formas comunes de respuesta
                    if isinstance(data, dict):
                        # texto directo
                        if "text" in data:
                            return data["text"]
                        # salida anidada.text
                        if "output" in data and isinstance(data["output"], dict) and "text" in data["output"]:
                            return data["output"]["text"]
                        # Gemini candidates[].content.parts[].text (candidatos de Gemini)
                        if "candidates" in data and isinstance(data["candidates"], list) and data["candidates"]:
                            cand0 = data["candidates"][0]
                            if isinstance(cand0, dict):
                                # algunos endpoints devuelven texto de nivel superior
                                if "text" in cand0:
                                    return cand0["text"]
                                # lenguaje generativo: content.parts
                                content = cand0.get("content")
                                if isinstance(content, dict):
                                    parts = content.get("parts")
                                    if isinstance(parts, list) and parts:
                                        part0 = parts[0]
                                        if isinstance(part0, dict) and "text" in part0:
                                            return part0["text"]
                        # fallback stringify si la estructura es desconocida
                        return str(data)
                    return r.text
                else:
                    # registrar cuerpo de error para depuraciÃ³n, pero intentar siguiente payload
                    last_exc = (r.status_code, r.text)
            except Exception as e:
                last_exc = e

        # si llegamos aquÃ­, todos los payloads fallaron; proporcionar error Ãºtil
        if isinstance(last_exc, tuple):
            status, body = last_exc
            raise RuntimeError(f"Request failed with status {status}: {body}")
        raise RuntimeError(f"Request failed: {last_exc}")

    # intentar varias formas comunes de respuesta
    if isinstance(data, dict):
        # comÃºn: {"text": "..."}
        if "text" in data:
            return data["text"]
        # otra forma comÃºn: {"output": {"text": "..."}}
        if "output" in data and isinstance(data["output"], dict) and "text" in data["output"]:
            return data["output"]["text"]
        # si la API devuelve una lista de fragmentos
        if "candidates" in data and isinstance(data["candidates"], list) and data["candidates"]:
            first = data["candidates"][0]
            if isinstance(first, dict) and "text" in first:
                return first["text"]

    # fallback: stringify toda la respuesta
    return str(data)


def main():
    # cargar memoria existente al inicio
    load_memory()
    
    app = ApplicationBuilder().token(TOKEN).build()

    # registrar manejadores
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_command))
    app.add_handler(CommandHandler("echo", echo_command))
    app.add_handler(CommandHandler("clear", clear_command))
    app.add_handler(CommandHandler("memory", memory_command))
    app.add_handler(CommandHandler("audiolimit", audio_limit_command))
    app.add_handler(CommandHandler("setaudiolimit", set_audio_limit_command))
    app.add_handler(CommandHandler("charthelp", chart_help_command))
    app.add_handler(CommandHandler("analyze", analyze_command))
    app.add_handler(CommandHandler("creargrafica", create_chart_command))
    app.add_handler(CommandHandler("datahistory", data_history_command))
    app.add_handler(CommandHandler("cleardata", clear_data_command))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))

    print("Bot con memoria en ejecuciÃ³n... presiona Ctrl+C para detenerlo.")

    # manejar cierre ordenado en Windows/UNIX signals
    def _stop(signum, frame):
        print("Deteniendo bot...")
        save_memory()  # guardar memoria antes de cerrar
        app.stop()

    try:
        signal.signal(signal.SIGINT, _stop)
        signal.signal(signal.SIGTERM, _stop)
    except Exception:
        # el manejo de seÃ±ales puede estar limitado en algunas plataformas, ignorar si falla
        pass

    app.run_polling()


if __name__ == "__main__":
    main()
